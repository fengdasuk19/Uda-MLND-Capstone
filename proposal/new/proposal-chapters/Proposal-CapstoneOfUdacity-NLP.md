# 毕业项目开题报告：自动文档分类

[TOC]

## 1. 项目背景

在互联网时代，越来越多的信息被上传到互联网上，下至个体上至各类组织，在进行大大小小各种决策时，都不可能忽视从互联网这个渠道获取的信息。面对浩如烟海的信息，要在更短的时间内得到更多、更准确的信息，仅靠人力查看与整理完全不现实；从而，各种相关的工具、技术应时而生，典型的例子包括搜索引擎、邮件过滤器、问答系统、消费者意见与情感分析技术（ref: http://52opencourse.com/222/斯坦福大学自然语言处理第六课-文本分类（text-classification） ）。而这些工具、技术的重要基础之一就是与文本分类相关的技术。

文本分类是基于文本内容将待定文本划分到一个或多个预先定义的类中的方法（ref: http://c.xml.org.cn/blog/uploadfile/20076211443809.PDF ），包括文本表示（预处理、索引、统计、特征表示）、分类器训练、评价与反馈等（ref: http://c.xml.org.cn/blog/uploadfile/20076211443809.PDF ）。文本表示方面的工作，包括词汇层面的独热编码（one-hot representation）、N 元语法（N-gram） 模型，句子、段落层面的词袋模型（Bag-of-words model）（ref: https://zh.wikipedia.org/wiki/词袋模型 ）等，也有词嵌入（Word Embedding）模型（ref: http://forum.yige.ai/thread/70 ）（ref: https://www.zhihu.com/question/32275069 ）（ref: http://weibo.com/3121700831/BsCvWgmPs ）如词汇层面的 Word2Vec，句子、段落层面的 Sentence2Vec、Doc2Vec 等（ref: http://www.cnblogs.com/maybe2030/p/5427148.html ）（ref: http://blog.csdn.net/wangongxi/article/details/51591031 ）；分类器的训练方法则包括 SVM、KNN、贝叶斯、基于有监督学习器的集成学习器等常见的有监督学习方法（ref: http://59.108.48.5/course/mining/12-13spring/参考文献/04-04%20基于机器学习的文本分类技术研究进展.pdf ）（ref: http://c.xml.org.cn/blog/uploadfile/20076211443809.PDF ）；评价方法则包括对于各分类器分类效果的查准率 P、查全率 R、F1 度量，以及对于总体而言的宏观平均（Macroaveraging）（给予每个分类同等权重从而求算术平均值，计算所有分类器的综合效果；用于测量小分类的效果）与对于总体而言的微观平均（Microaveraging）（给予每篇文档同等权重从而求算术平均值，计算每篇文档分类结果的综合效果；用于测量大分类的效果）（ref: http://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-text-classification-1.html ）（ref: 周志华西瓜书 2.3.2 ）

本文作者对搜索引擎设计技术与情感计算技术感兴趣，因此选择研究此课题，以便为后续相关研究与设计做准备。

## 2. 问题描述

总的来说，本项目要解决的问题：

> 如何设计一套文本分类模型，能够把 18000 多条新闻较准确地分配到 20 个主题类别中？

问题分解为 3 个部分：

1. 研究建立文本表示模型的方法：准备用基于词袋模型（Bag-of-Words）的 TF-IDF 方法，以及基于词嵌入模型（Word Embedding）的 Doc2Vec 方法，分别为文章建立表示模型
2. 研究训练文本分类器的方法：这是一个有监督学习问题，需要对于已经给定的输入语料选择恰当的分类器训练方法。
3. 对于经过训练后，文本表示模型与分类器的多种结合组成的分类系统，评估这些分类系统的实际分类效果

## 3. 输入数据

ch3

## 4. 解决办法

0. 【数据预处理】将待训练集和测试集的文本进行同样的清洗，即
    + 清除其他所有字符，只保留由小写字母 a-z 组成的单词、单一空格（将不在 a-z 之间的字符也一律转换为空格）
1. 【特征抽取与文本表示】从文本数据集中抽取表示文本所需的特征，然后在文本数据集上用这些抽取出的特征重新表示文本数据集，包括
    + 使用**TF-IDF** 方法抽取特征，建立表示模型 1，包括如下步骤：
    + 使用**词嵌入**（Word embedding）方法（在这里，具体使用 Doc2Vec）抽取特征，建立表示模型 2
2. 【分类器训练】对已经建立的表示模型，在每个模型上分别使用一些有监督学习方法在训练数据上分别训练出一定数量的分类器，包括这 3 种分类器训练模型：
    + SVM（支持向量机）
    + 朴素贝叶斯分类器
    + 神经网络
3. 【性能评估】对上述分类器进行如下评估：
    1. 对于上述每种表示模型：比较同一文本表示模型下不同训练方法的训练效果
    2. 在每种表示模型的语境下各选出分类效果最好的那个分类器，并进行比较
    3. 评估指标见下

## 5. 评估指标

综合考虑下述 3 个指标：

+ F1：$F_{1} = \frac{2PR}{P+R}$，其中同时考虑了查准率（Precision） $P = \frac{TP}{TP + FP}$ 与查全率（Recall） $R = \frac{TP}{TP + FN}$
+ 训练时间 $t_{train}$：训练分类器达到标准所耗费的时间
+ 分类时间 $t_{test}$：训练出的分类器在测试数据上进行分类所耗费的时间

在最终评估分类器性能时，使用下述公式来综合考虑这 3 个指标：

+ $score(F_{1}, t_{train}, t_{test}) = \frac{F_1}{t_{train} * t_{test}}$

这个指标 $score$（得分） 是我自己设计的，其含义是：

+ $F_{1}$ 放在分子处，值越高，即综合考虑了查准率 $P$ 和查全率 $R$ 的指标得分越高，模型总得分越高，即给予模型越好的评价：我希望训练得到一个在 $P$ 和 $R$ 上效果都不错的分类器
+ $t_{train} * t_{test}$ 放在分子处，即综合考虑了训练时间 $t_{train}$ 和实际分类耗时 $t_{test}$ 的影响：我希望训练得到一个训练速度和实际工作速度都较好的分类器。无论是训练耗时 $t_{train}$ 太长、实际使用时耗时 $t_{test}$ 较短，还是训练耗时 $t_{train}$ 较短、实际使用时耗时 $t_{test}$ 太长，都不是太好的模型。

## 6. 基准模型

ch6

## 7. 设计大纲

ch7