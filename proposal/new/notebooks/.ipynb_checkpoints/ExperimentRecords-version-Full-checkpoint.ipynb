{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 更新日志\n",
    "\n",
    "+ 【2017/05/11】\n",
    "    - 重新梳理前期实验结果，并整合到该份报告中\n",
    "    - 前期实验报告参见同一目录下的其他以 `trial_` 开头的 `.ipynb` 文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 备注\n",
    "\n",
    "1. 搜索该符号以定位到报告中待完善的部分：。。。\n",
    "2. 稍后可考虑将部分代码包装成 Python 脚本，以模块的形式导入，使整个 notebook 更简洁？或者不这样处理，从而使读者更方便阅读（而不用另外切换于多个页面之间）？\n",
    "3. 。。。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "\n",
    "1. (#miscellaneous) [20 Newsgroup Document Classification Report](http://cn-static.udacity.com/mlnd/Capstone_Poject_Sample01.pdf)\n",
    "2. (#word2vec, #tensorflow) [Vector Representations of Words](https://www.tensorflow.org/tutorials/word2vec)\n",
    "3. (#word2vec) [Distributed Representations of Words and Phrases and their Compositionality](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)\n",
    "4. (#word2vec, #gensim) [models.word2vec – Deep learning with word2vec](https://radimrehurek.com/gensim/models/word2vec.html)\n",
    "5. (#CNN, #tensorflow) [Deep MNIST for Experts](https://www.tensorflow.org/get_started/mnist/pros)\n",
    "6. (#text8) [text8](http://mattmahoney.net/dc/textdata)\n",
    "7. 。。。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验模块规划\n",
    "\n",
    "粗略规划如下，稍后精细整理：实现下述共计 8 种「表示 + 训练」组合\n",
    "\n",
    "表示模型 | 分类器训练法\n",
    "---------------|---------------------\n",
    "BOW + TF-IDF | SVM\n",
    "                     | DNN\n",
    "                     | LDA\n",
    "Word2Vec      | SVM\n",
    "                     | DNN\n",
    "                     | CNN\n",
    "                     \n",
    "其中：\n",
    "+ 名词解释\n",
    "    - 表示模型\n",
    "        * BOW：Bag-of-Words，词袋模型\n",
    "        * TF-IDF：Term Frequency - Inverse Document Frequency，文档-逆文档频率\n",
    "    - 分类器训练法\n",
    "        * SVM：Support Vector Machine，支持向量机\n",
    "        * LDA：Latent Dirichlet Allocation，隐含狄利克雷分布\n",
    "        * DNN：Deep Neural Network，深度神经网络（普通的多层感知机构成的多层神经网络）\n",
    "        * CNN：Convolution Neural Network，卷积神经网络\n",
    "+ 训练工具\n",
    "    - 表示模型\n",
    "        * BOW+TF-IDF：使用 scikit-learn 建模\n",
    "        * Word2Vec：使用 gensim 与 TensorFlow 建模\n",
    "    - 分类器训练法\n",
    "        * 传统算法：SVM 使用 scikit-learn 训练，LDA 使用 scikit-learn 或 gensim 进行训练。。。\n",
    "        * 神经网络算法：DNN, CNN：使用 TensorFlow 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验流程规划\n",
    "\n",
    "1. 模块导入\n",
    "2. 数据预处理（通用预处理）\n",
    "  + 对文本进行清洗，包括但不限于去除特殊符号、进行大小写转换等工作，最终使文本中只包含：由小写字母 a-z 组成的单词、单一空格\n",
    "  + 不在 a-z 之间的字符将一律被转换为空格\n",
    "3. 文本表示建模\n",
    "  + BOW+TF-IDF 表示：\n",
    "      1. 使用 scikit-learn，在待学习样本的语料上，进行建立词袋（BOW）、计算 TF-IDF\n",
    "      2. 通过使用 BOW+TF-IDF 向量表示文档中的每个词，从而表示每篇文档\n",
    "      3. 每篇文档对应的标签独热（one-hot）向量化\n",
    "  + Word2Vec 表示：\n",
    "      1. 分别使用 gensim 和 TensorFlow 中的每一种，分别在 text8 的基础上、在待学习样本的基础上，建立词嵌入（word embedding）模型（Word2Vec）\n",
    "          + 即：训练出 gensim+text8, gensim+待学习样本, TensorFlow+text8, TensorFlow+待学习样本 共计 4 种表示模型\n",
    "          + 使用 Skip-Gram 方法进行建模\n",
    "      2. 通过使用 Word2Vec 向量表示文档中的每个词，然后建立 2 种文档表示模型：\n",
    "          + 求这些词向量的和，以求和向量表示每一篇文档；对于不在词汇表中的词，以某常量代替——具体而言，可指定为加入零向量，或在求和向量乘上某个常量系数\n",
    "          + 对于上述求和向量进行求算术平均，使用算术平均向量表示每一篇文档；对于不在词汇表中的词，同上述处理方法\n",
    "      3. 每篇文档对应的标签独热（one-hot）向量化\n",
    "4. 分类器训练\n",
    "  + 传统算法：SVM 使用 scikit-learn 训练，LDA 使用 scikit-learn 或 gensim 进行训练。。。\n",
    "  + 神经网络算法：DNN, CNN：使用 TensorFlow 训练\n",
    "5. 分类器评估\n",
    "  + 对于传统算法：\n",
    "    - 使用 sckit-learn 提供的 GridSearchCV 与 LearningCurve 方法寻找最优参数组合\n",
    "    - 使用 scikit-learn 提供的 accuracy_score（查准率 P） 与 f1_score（F1 分数，同时考察了查准率 P 与查全率 R） 评估训练结果\n",
    "  + 对于神经网络算法：\n",
    "    - 暂定手工选择一组参数进行训练；待考察是否可使用 GridSearchCV 与 LearningCurve 进行参数组合寻找最优参数组合\n",
    "    - 暂定使用手工编写的方法计算查准率 P、查全率 R、F1 分数；待考察是否可对数据格式进行一定程度上的转换或存储，以使用上述提及的 scikit-learn 提供的评估工具"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验记录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW+TF-IDF 表示法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec 表示法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 对于同一种分类器训练法，不同表示模型对结果的影响"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 对于同一种表示模型，不同训练模型对结果的影响"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 综合来看，「表示模型 + 分类器」组合的效果评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 展望"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
