{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -2. 更新日志\n",
    "\n",
    "+ 【2017/05/11】\n",
    "    - 重新梳理前期实验结果，并整合到该份报告中\n",
    "    - 前期实验报告参见同一目录下的其他以 `trial_` 开头的 `.ipynb` 文件\n",
    "+ 【2017/05/21】\n",
    "    - 完成最后一份与词嵌入（word embeding）模型有关的文本表示模型试验，正式开始整合\n",
    "        * 对应的试验文件名为：`gensim-corpus-WordClustering-DataRecordWrapper.ipynb`\n",
    "+ 【2017/05/23】\n",
    "    - 删除本 notebook 中所有代码模块，准备利用 Jupyter Notebook 的 magic commd `%%run jupyter_notebook.ipynb` 进行模块化，从而使该记录本更干净\n",
    "    - 修改第 5 节【5. 总结】部分的结构\n",
    "+ 【2017/05/26】\n",
    "    - 删除 GloVe 计划，重新整理笔记本规划"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -1. 备注\n",
    "\n",
    "1. 搜索该符号以定位到报告中待完善的部分：。。。\n",
    "2. 。。。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 参考文献\n",
    "\n",
    "1. (#miscellaneous) [20 Newsgroup Document Classification Report](http://cn-static.udacity.com/mlnd/Capstone_Poject_Sample01.pdf)\n",
    "2. (#word2vec, #tensorflow) [Vector Representations of Words](https://www.tensorflow.org/tutorials/word2vec)\n",
    "3. (#word2vec) [Distributed Representations of Words and Phrases and their Compositionality](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)\n",
    "4. (#word2vec, #gensim) [models.word2vec – Deep learning with word2vec](https://radimrehurek.com/gensim/models/word2vec.html)\n",
    "5. (#CNN, #tensorflow) [Deep MNIST for Experts](https://www.tensorflow.org/get_started/mnist/pros)\n",
    "6. (#text8) [text8](http://mattmahoney.net/dc/textdata)\n",
    "7. (#tricks) [[译]27 个Jupyter Notebook的小提示与技巧](http://liuchengxu.org/pelican-blog/jupyter-notebook-tips.html)\n",
    "8. 。。。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 实验模块规划\n",
    "\n",
    "粗略规划如下，稍后精细整理：实现下述共计 15 种「表示 + 训练」组合\n",
    "\n",
    "词汇模型 | 文档表示模型 | 分类器训练法\n",
    "---------------|---------------------|---------------------\n",
    "BOW              | TFIDF | SVM\n",
    "                     | TFIDF | NB(Gaussian NB)\n",
    "                     | TFIDF | RF\n",
    "                     | TFIDF-LSA | SVM\n",
    "                     | TFIDF-LSA | NB(Gaussian NB)\n",
    "                     | TFIDF-LSA | RF\n",
    "Word2Vec      | arithmatic mean representation | SVM\n",
    "                     | arithmatic mean representation | DNN\n",
    "                     | arithmatic mean representation | CNN\n",
    "                     | word-clustering (TF\\*IDF) | SVM\n",
    "                     | word-clustering (TF\\*IDF) | DNN\n",
    "                     | word-clustering (TF\\*IDF) | CNN\n",
    "None             | Doc2Vec | SVM\n",
    "                    | Doc2Vec | DNN\n",
    "                    | Doc2Vec | CNN\n",
    "\n",
    "其中：\n",
    "+ 名词解释\n",
    "    - 词汇表示模型\n",
    "        * BOW：Bag-of-Words，词袋模型\n",
    "        * TF-IDF：Term Frequency - Inverse Document Frequency，文档-逆文档频率，其中\n",
    "            - TF：词频，指该[词汇在文档中出现的原始频数](http://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting)\n",
    "            - IDF：逆文档频率，指 $idf(d, t) = log( \\frac{n}{df(d, t)} ) + 1$（该公式为 sklearn 中对 $idf(d, t)$的[实现](https://github.com/scikit-learn/scikit-learn/blob/14031f6/sklearn/feature_extraction/text.py#L1017)），其中 $df(d, t)$ 为[包含词汇 $t$ 的文档 $d$ 数目](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer)\n",
    "    - 文档表示模型\n",
    "        * Plain BOW：直接用词袋向量表示每一篇文档，向量中每个维度的值为该词的 TF \\* IDF 值\n",
    "        * LSA：潜在语义分析\n",
    "        * arithmatic mean representation：均值表示法，即将该文档中每个词的词嵌入向量相加后求均值，用均值向量来表示文档\n",
    "        * word-clustering (TF\\*IDF)：基于词嵌入向量的聚类表示（基于TF\\*IDF），又称「概念袋」（Bag-of-Concepts）法（基于 TF\\*IDF）\n",
    "        * Doc2Vec：文档嵌入向量表示\n",
    "    - 分类器训练法\n",
    "        * SVM：Support Vector Machine，支持向量机\n",
    "        * NB(Gaussian NB)：NB(Naive Bayes) 朴素贝叶斯；Gaussian NB 高斯朴素贝叶斯（认为特征项服从于高斯分布，即正态分布）\n",
    "        * RF：RandomForest，随机森林\n",
    "        * DNN：Deep Neural Network，深度神经网络（普通的多层感知机构成的多层神经网络）\n",
    "        * CNN：Convolution Neural Network，卷积神经网络\n",
    "+ 训练工具\n",
    "    - 词汇模型\n",
    "        * BOW+TF-IDF：使用 scikit-learn 建模\n",
    "        * Word2Vec：使用 gensim 与 TensorFlow 建模\n",
    "    - 文档表示模型\n",
    "        * sklearn\n",
    "        * 手动编写代码\n",
    "    - 分类器训练法\n",
    "        * 传统算法：SVM, LSA, LDA 使用 scikit-learn 训练\n",
    "        * 神经网络算法：DNN, CNN：使用 TensorFlow 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 实验流程规划\n",
    "\n",
    "1. 模块导入\n",
    "2. 数据预处理（通用预处理）\n",
    "  + 对文本进行清洗，包括但不限于去除特殊符号、进行大小写转换等工作，最终使文本中只包含：由小写字母 a-z 组成的单词、单一空格\n",
    "  + 不在 a-z 之间的字符将一律被转换为空格\n",
    "3. 文本表示建模\n",
    "  + 不基于任何词汇表示，直接使用 Doc2Vec 建立文档嵌入向量\n",
    "  + 基于 BOW 词汇表示，使用 TF-IDF 建立 3 种文档表示模型：\n",
    "      1. 读入原始语料并保存\n",
    "      2. 使用 scikit-learn，在原始语料的基础上，进行建立词袋（BOW）、计算 TF-IDF\n",
    "      3. 文档表示建模\n",
    "          - 【法 1】通过使用 BOW+TF-IDF 向量表示文档中的每个词，从而表示每篇文档（包括所有语料：训练集和测试集）\n",
    "          - 【法 2】通过在由 BOW+TF-IDF 向量组成的矩阵上进行 LSA，从而表示每篇文档（包括所有语料：训练集和测试集）\n",
    "  + 基于 Word2Vec 词汇表示，使用 3 种方法建立文档表示模型：\n",
    "      1. 分别使用 gensim 和 TensorFlow 中的每一种，分别在 text8 的基础上、在待学习样本（corpus）的基础上，建立词嵌入（word embedding）模型：Word2Vec\n",
    "          + 即：训练出 gensim+text8, gensim+待学习样本, TensorFlow+text8, TensorFlow+待学习样本 共计 4 种表示模型\n",
    "          + 使用 Skip-Gram 方法进行建模\n",
    "      2. 文档表示建模\n",
    "          + 【法 1】通过使用 Word2Vec 向量表示文档中的每个词，求这些词向量的和，对于求和向量进行求算术平均，使用算术平均向量表示每一篇文档\n",
    "              - 对于不在词汇表中的词，以某常量代替——具体而言，可指定为加入零向量，或在求和向量乘上某个常量系数\n",
    "          + 【法 2】通过对学习到的 Word2Vec 向量进行聚类，得到若干「概念袋」（Bag-of-Concepts）（类比「词袋」，Bag-of-Concepts），用然后对「概念袋」的每一个维度进行计数（遍历文档中的每个词，聚类预测其所在的「概念维度」），进行 TF\\*IDF 计算，然后用 TF\\*IDF 值来表示每一篇文档，从而表示每一篇文档\n",
    "              - 对于不在词汇表中的词，可以指向同一维度 `UNK` 进行计数，最后的 「概念袋」中可考虑使用或不使用该维度来表示文档\n",
    "      3. 在使用神经网络算法进行训练前，对每篇文档对应的标签独热（one-hot）向量化\n",
    "4. 分类器训练\n",
    "  + 传统算法：SVM, LSA 使用 scikit-learn 训练\n",
    "  + 神经网络算法：DNN, CNN：使用 TensorFlow 训练\n",
    "5. 分类器评估\n",
    "  + 对于传统算法：\n",
    "    - 使用 sckit-learn 提供的 GridSearchCV 与 LearningCurve 方法寻找最优参数组合\n",
    "    - 使用 scikit-learn 提供的 accuracy_score（查准率 P） 与 f1_score（F1 分数，同时考察了查准率 P 与查全率 R） 评估训练结果\n",
    "  + 对于神经网络算法：\n",
    "    - 暂定手工选择一组参数进行训练；待考察是否可使用 GridSearchCV 与 LearningCurve 进行参数组合寻找最优参数组合\n",
    "    - 暂定使用手工编写的方法计算查准率 P、查全率 R、F1 分数；待考察是否可对数据格式进行一定程度上的转换或存储，以使用上述提及的 scikit-learn 提供的评估工具"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 实验记录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 原始数据修改说明\n",
    "\n",
    "这里的 CSV 基于原始数据 'trial5_all.csv' 修改而成，修改而部分为：\n",
    "\n",
    "1. 删去所有 LDA、BagOfConcepts 表示模型的数据。（原因：不纳入分析范围）\n",
    "2. 将所有 `BOW+TF*IDF` 模型的 `model.word` 从 `BOW` 改成了 `NO`，把所有 `Doc2Vec` 模型的 `model.word` 从 `none-Doc2Vec` 改成了 `NO`（原因：实际上这两种模型确实没有对词汇建模，没必要用这个方式区分）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model.source</th>\n",
       "      <th>useStopwords</th>\n",
       "      <th>tool.word</th>\n",
       "      <th>model.word</th>\n",
       "      <th>model.document</th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro-F1</th>\n",
       "      <th>micro-F1</th>\n",
       "      <th>time.format.model</th>\n",
       "      <th>time.format.train</th>\n",
       "      <th>time.format.evaluate</th>\n",
       "      <th>time.format.all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>TF*IDF-LSA</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.731382</td>\n",
       "      <td>0.733431</td>\n",
       "      <td>0.731382</td>\n",
       "      <td>0:00:05.716000</td>\n",
       "      <td>0:00:00.015000</td>\n",
       "      <td>0:00:00.024600</td>\n",
       "      <td>0:00:05.755600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>TF*IDF-LSA</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.707756</td>\n",
       "      <td>0.707246</td>\n",
       "      <td>0.707756</td>\n",
       "      <td>0:00:05.716000</td>\n",
       "      <td>0:00:00.379000</td>\n",
       "      <td>0:00:00.024000</td>\n",
       "      <td>0:00:06.119000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>TF*IDF-LSA</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.897791</td>\n",
       "      <td>0.898563</td>\n",
       "      <td>0.897791</td>\n",
       "      <td>0:00:05.716000</td>\n",
       "      <td>0:00:00.158000</td>\n",
       "      <td>0:00:00.017300</td>\n",
       "      <td>0:00:05.891300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>TF*IDF-Plain</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.842322</td>\n",
       "      <td>0.840255</td>\n",
       "      <td>0.842322</td>\n",
       "      <td>0:00:05.066000</td>\n",
       "      <td>0:00:00.044000</td>\n",
       "      <td>0:00:00.063300</td>\n",
       "      <td>0:00:05.173300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>TF*IDF-Plain</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.821777</td>\n",
       "      <td>0.823668</td>\n",
       "      <td>0.821777</td>\n",
       "      <td>0:00:05.066000</td>\n",
       "      <td>0:00:00.223000</td>\n",
       "      <td>0:00:00.025900</td>\n",
       "      <td>0:00:05.314900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>TF*IDF-Plain</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.887519</td>\n",
       "      <td>0.888503</td>\n",
       "      <td>0.887519</td>\n",
       "      <td>0:00:05.066000</td>\n",
       "      <td>0:00:00.115000</td>\n",
       "      <td>0:00:00.025400</td>\n",
       "      <td>0:00:05.206400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>corpus</td>\n",
       "      <td>yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>BOW</td>\n",
       "      <td>TF*IDF-LSA</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.781498</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0:00:05.607000</td>\n",
       "      <td>0:00:00.012600</td>\n",
       "      <td>0:00:00.025100</td>\n",
       "      <td>0:00:05.644700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>corpus</td>\n",
       "      <td>yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>BOW</td>\n",
       "      <td>TF*IDF-LSA</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.754494</td>\n",
       "      <td>0.754016</td>\n",
       "      <td>0.754494</td>\n",
       "      <td>0:00:05.607000</td>\n",
       "      <td>0:00:00.380000</td>\n",
       "      <td>0:00:00.023400</td>\n",
       "      <td>0:00:06.010400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>corpus</td>\n",
       "      <td>yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>BOW</td>\n",
       "      <td>TF*IDF-LSA</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.896251</td>\n",
       "      <td>0.897107</td>\n",
       "      <td>0.896251</td>\n",
       "      <td>0:00:05.607000</td>\n",
       "      <td>0:00:00.149000</td>\n",
       "      <td>0:00:00.026600</td>\n",
       "      <td>0:00:05.782600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>corpus</td>\n",
       "      <td>yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>BOW</td>\n",
       "      <td>TF*IDF-Plain</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.843862</td>\n",
       "      <td>0.841737</td>\n",
       "      <td>0.843862</td>\n",
       "      <td>0:00:04.857000</td>\n",
       "      <td>0:00:00.041000</td>\n",
       "      <td>0:00:00.063600</td>\n",
       "      <td>0:00:04.961600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>corpus</td>\n",
       "      <td>yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>BOW</td>\n",
       "      <td>TF*IDF-Plain</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.837699</td>\n",
       "      <td>0.839667</td>\n",
       "      <td>0.837699</td>\n",
       "      <td>0:00:04.857000</td>\n",
       "      <td>0:00:00.205000</td>\n",
       "      <td>0:00:00.026200</td>\n",
       "      <td>0:00:05.088200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>corpus</td>\n",
       "      <td>yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>BOW</td>\n",
       "      <td>TF*IDF-Plain</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.889574</td>\n",
       "      <td>0.890771</td>\n",
       "      <td>0.889574</td>\n",
       "      <td>0:00:04.857000</td>\n",
       "      <td>0:00:00.082000</td>\n",
       "      <td>0:00:00.030000</td>\n",
       "      <td>0:00:04.969000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.864920</td>\n",
       "      <td>0.861901</td>\n",
       "      <td>0.864920</td>\n",
       "      <td>2:39:40.700000</td>\n",
       "      <td>0:04:34.402000</td>\n",
       "      <td>0:00:05.820000</td>\n",
       "      <td>2:44:20.922000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>DNN</td>\n",
       "      <td>0.906523</td>\n",
       "      <td>0.906468</td>\n",
       "      <td>0.906523</td>\n",
       "      <td>2:39:40.700000</td>\n",
       "      <td>0:03:06</td>\n",
       "      <td>0:00:04.860000</td>\n",
       "      <td>2:42:51.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.923472</td>\n",
       "      <td>0.923301</td>\n",
       "      <td>0.923472</td>\n",
       "      <td>2:39:40.700000</td>\n",
       "      <td>0:00:02.120000</td>\n",
       "      <td>0:00:00.023100</td>\n",
       "      <td>2:39:42.843100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>BagOfConcepts-TFIDF</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.288649</td>\n",
       "      <td>0.277409</td>\n",
       "      <td>0.288649</td>\n",
       "      <td>2:52:44</td>\n",
       "      <td>0:01:12.448000</td>\n",
       "      <td>0:00:03.590000</td>\n",
       "      <td>2:54:00.038000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>BagOfConcepts-TFIDF</td>\n",
       "      <td>DNN</td>\n",
       "      <td>0.286081</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.286081</td>\n",
       "      <td>2:52:44</td>\n",
       "      <td>0:01:12</td>\n",
       "      <td>0:00:01.500000</td>\n",
       "      <td>2:53:57.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>BagOfConcepts-TFIDF</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.281972</td>\n",
       "      <td>0.199431</td>\n",
       "      <td>0.281972</td>\n",
       "      <td>2:52:44</td>\n",
       "      <td>0:00:00.290000</td>\n",
       "      <td>0:00:00.108000</td>\n",
       "      <td>2:52:44.398000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.904468</td>\n",
       "      <td>0.903780</td>\n",
       "      <td>0.904468</td>\n",
       "      <td>0:07:55.180000</td>\n",
       "      <td>0:04:41.409000</td>\n",
       "      <td>0:00:05.830000</td>\n",
       "      <td>0:12:42.419000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>DNN</td>\n",
       "      <td>0.933744</td>\n",
       "      <td>0.934022</td>\n",
       "      <td>0.933744</td>\n",
       "      <td>0:07:55.180000</td>\n",
       "      <td>0:03:00</td>\n",
       "      <td>0:00:04.850000</td>\n",
       "      <td>0:11:00.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.939908</td>\n",
       "      <td>0.940072</td>\n",
       "      <td>0.939908</td>\n",
       "      <td>0:07:55.180000</td>\n",
       "      <td>0:00:01.660000</td>\n",
       "      <td>0:00:00.068900</td>\n",
       "      <td>0:07:56.908900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>BagOfConcepts-TFIDF</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.409348</td>\n",
       "      <td>0.406807</td>\n",
       "      <td>0.409348</td>\n",
       "      <td>0:18:20</td>\n",
       "      <td>0:01:15.392000</td>\n",
       "      <td>0:00:03.320000</td>\n",
       "      <td>0:19:38.712000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>BagOfConcepts-TFIDF</td>\n",
       "      <td>DNN</td>\n",
       "      <td>0.511556</td>\n",
       "      <td>0.527785</td>\n",
       "      <td>0.511556</td>\n",
       "      <td>0:18:20</td>\n",
       "      <td>0:00:58.300000</td>\n",
       "      <td>0:00:01.270000</td>\n",
       "      <td>0:19:19.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>BagOfConcepts-TFIDF</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.463214</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0:18:20</td>\n",
       "      <td>0:00:00.051000</td>\n",
       "      <td>0:00:00.016000</td>\n",
       "      <td>0:18:20.067000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.856703</td>\n",
       "      <td>0.859630</td>\n",
       "      <td>0.856703</td>\n",
       "      <td>0:32:46.600000</td>\n",
       "      <td>0:04:40.397000</td>\n",
       "      <td>0:00:05.720000</td>\n",
       "      <td>0:37:32.717000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>DNN</td>\n",
       "      <td>0.901387</td>\n",
       "      <td>0.901441</td>\n",
       "      <td>0.901387</td>\n",
       "      <td>0:32:46.600000</td>\n",
       "      <td>0:03:06</td>\n",
       "      <td>0:00:04.550000</td>\n",
       "      <td>0:35:57.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.919877</td>\n",
       "      <td>0.919649</td>\n",
       "      <td>0.919877</td>\n",
       "      <td>0:32:46.600000</td>\n",
       "      <td>0:00:01.420000</td>\n",
       "      <td>0:00:00.031100</td>\n",
       "      <td>0:32:48.051100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>BagOfConcepts-TFIDF</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.742681</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.742681</td>\n",
       "      <td>1:05:33</td>\n",
       "      <td>0:01:22.426000</td>\n",
       "      <td>0:00:03.470000</td>\n",
       "      <td>1:06:58.896000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>BagOfConcepts-TFIDF</td>\n",
       "      <td>DNN</td>\n",
       "      <td>0.829995</td>\n",
       "      <td>0.830627</td>\n",
       "      <td>0.829995</td>\n",
       "      <td>1:05:33</td>\n",
       "      <td>0:01:12</td>\n",
       "      <td>0:00:09</td>\n",
       "      <td>1:06:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>BagOfConcepts-TFIDF</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.825372</td>\n",
       "      <td>0.825952</td>\n",
       "      <td>0.825372</td>\n",
       "      <td>1:05:33</td>\n",
       "      <td>0:00:00.470000</td>\n",
       "      <td>0:00:00.100000</td>\n",
       "      <td>1:05:33.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909003</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0:01:42.750000</td>\n",
       "      <td>0:04:27.397000</td>\n",
       "      <td>0:00:05.740000</td>\n",
       "      <td>0:06:15.887000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>DNN</td>\n",
       "      <td>0.916795</td>\n",
       "      <td>0.917043</td>\n",
       "      <td>0.916795</td>\n",
       "      <td>0:01:42.750000</td>\n",
       "      <td>0:02:56</td>\n",
       "      <td>0:00:04.680000</td>\n",
       "      <td>0:04:43.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.930149</td>\n",
       "      <td>0.930138</td>\n",
       "      <td>0.930149</td>\n",
       "      <td>0:01:42.750000</td>\n",
       "      <td>0:00:01.150000</td>\n",
       "      <td>0:00:00.021300</td>\n",
       "      <td>0:01:43.921300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>BagOfConcepts-TFIDF</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.825886</td>\n",
       "      <td>0.828683</td>\n",
       "      <td>0.825886</td>\n",
       "      <td>0:15:11</td>\n",
       "      <td>0:01:19.388000</td>\n",
       "      <td>0:00:03.280000</td>\n",
       "      <td>0:16:33.668000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>BagOfConcepts-TFIDF</td>\n",
       "      <td>DNN</td>\n",
       "      <td>0.896251</td>\n",
       "      <td>0.896160</td>\n",
       "      <td>0.896251</td>\n",
       "      <td>0:15:11</td>\n",
       "      <td>0:01:01</td>\n",
       "      <td>0:00:01.210000</td>\n",
       "      <td>0:16:13.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>BagOfConcepts-TFIDF</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.895737</td>\n",
       "      <td>0.895506</td>\n",
       "      <td>0.895737</td>\n",
       "      <td>0:15:11</td>\n",
       "      <td>0:00:00.054600</td>\n",
       "      <td>0:00:00.019100</td>\n",
       "      <td>0:15:11.073700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>NO</td>\n",
       "      <td>Doc2Vec</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.500770</td>\n",
       "      <td>0.482545</td>\n",
       "      <td>0.500770</td>\n",
       "      <td>0:09:03.000005</td>\n",
       "      <td>0:04:07.422000</td>\n",
       "      <td>0:00:06</td>\n",
       "      <td>0:13:16.422005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>NO</td>\n",
       "      <td>Doc2Vec</td>\n",
       "      <td>DNN</td>\n",
       "      <td>0.714946</td>\n",
       "      <td>0.710270</td>\n",
       "      <td>0.714946</td>\n",
       "      <td>0:09:03.000005</td>\n",
       "      <td>0:03:01</td>\n",
       "      <td>0:00:04.370000</td>\n",
       "      <td>0:12:08.370005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>NO</td>\n",
       "      <td>Doc2Vec</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.724396</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0:09:03.000005</td>\n",
       "      <td>0:00:10.100000</td>\n",
       "      <td>0:00:00.353000</td>\n",
       "      <td>0:09:13.453005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model.source useStopwords   tool.word model.word       model.document  \\\n",
       "0        corpus           NO          NO         NO           TF*IDF-LSA   \n",
       "1        corpus           NO          NO         NO           TF*IDF-LSA   \n",
       "2        corpus           NO          NO         NO           TF*IDF-LSA   \n",
       "3        corpus           NO          NO         NO         TF*IDF-Plain   \n",
       "4        corpus           NO          NO         NO         TF*IDF-Plain   \n",
       "5        corpus           NO          NO         NO         TF*IDF-Plain   \n",
       "6        corpus          yes          NO        BOW           TF*IDF-LSA   \n",
       "7        corpus          yes          NO        BOW           TF*IDF-LSA   \n",
       "8        corpus          yes          NO        BOW           TF*IDF-LSA   \n",
       "9        corpus          yes          NO        BOW         TF*IDF-Plain   \n",
       "10       corpus          yes          NO        BOW         TF*IDF-Plain   \n",
       "11       corpus          yes          NO        BOW         TF*IDF-Plain   \n",
       "12        text8           NO  TensorFlow   Word2Vec       ArithmeticMean   \n",
       "13        text8           NO  TensorFlow   Word2Vec       ArithmeticMean   \n",
       "14        text8           NO  TensorFlow   Word2Vec       ArithmeticMean   \n",
       "15        text8           NO  TensorFlow   Word2Vec  BagOfConcepts-TFIDF   \n",
       "16        text8           NO  TensorFlow   Word2Vec  BagOfConcepts-TFIDF   \n",
       "17        text8           NO  TensorFlow   Word2Vec  BagOfConcepts-TFIDF   \n",
       "18       corpus           NO  TensorFlow   Word2Vec       ArithmeticMean   \n",
       "19       corpus           NO  TensorFlow   Word2Vec       ArithmeticMean   \n",
       "20       corpus           NO  TensorFlow   Word2Vec       ArithmeticMean   \n",
       "21       corpus           NO  TensorFlow   Word2Vec  BagOfConcepts-TFIDF   \n",
       "22       corpus           NO  TensorFlow   Word2Vec  BagOfConcepts-TFIDF   \n",
       "23       corpus           NO  TensorFlow   Word2Vec  BagOfConcepts-TFIDF   \n",
       "24        text8           NO      gensim   Word2Vec       ArithmeticMean   \n",
       "25        text8           NO      gensim   Word2Vec       ArithmeticMean   \n",
       "26        text8           NO      gensim   Word2Vec       ArithmeticMean   \n",
       "27        text8           NO      gensim   Word2Vec  BagOfConcepts-TFIDF   \n",
       "28        text8           NO      gensim   Word2Vec  BagOfConcepts-TFIDF   \n",
       "29        text8           NO      gensim   Word2Vec  BagOfConcepts-TFIDF   \n",
       "30       corpus           NO      gensim   Word2Vec       ArithmeticMean   \n",
       "31       corpus           NO      gensim   Word2Vec       ArithmeticMean   \n",
       "32       corpus           NO      gensim   Word2Vec       ArithmeticMean   \n",
       "33       corpus           NO      gensim   Word2Vec  BagOfConcepts-TFIDF   \n",
       "34       corpus           NO      gensim   Word2Vec  BagOfConcepts-TFIDF   \n",
       "35       corpus           NO      gensim   Word2Vec  BagOfConcepts-TFIDF   \n",
       "36       corpus           NO      gensim         NO              Doc2Vec   \n",
       "37       corpus           NO      gensim         NO              Doc2Vec   \n",
       "38       corpus           NO      gensim         NO              Doc2Vec   \n",
       "\n",
       "                classifier  accuracy  macro-F1  micro-F1 time.format.model  \\\n",
       "0               GaussianNB  0.731382  0.733431  0.731382    0:00:05.716000   \n",
       "1   RandomForestClassifier  0.707756  0.707246  0.707756    0:00:05.716000   \n",
       "2                      SVM  0.897791  0.898563  0.897791    0:00:05.716000   \n",
       "3               GaussianNB  0.842322  0.840255  0.842322    0:00:05.066000   \n",
       "4   RandomForestClassifier  0.821777  0.823668  0.821777    0:00:05.066000   \n",
       "5                      SVM  0.887519  0.888503  0.887519    0:00:05.066000   \n",
       "6               GaussianNB  0.779661  0.781498  0.779661    0:00:05.607000   \n",
       "7   RandomForestClassifier  0.754494  0.754016  0.754494    0:00:05.607000   \n",
       "8                      SVM  0.896251  0.897107  0.896251    0:00:05.607000   \n",
       "9               GaussianNB  0.843862  0.841737  0.843862    0:00:04.857000   \n",
       "10  RandomForestClassifier  0.837699  0.839667  0.837699    0:00:04.857000   \n",
       "11                     SVM  0.889574  0.890771  0.889574    0:00:04.857000   \n",
       "12                     CNN  0.864920  0.861901  0.864920    2:39:40.700000   \n",
       "13                     DNN  0.906523  0.906468  0.906523    2:39:40.700000   \n",
       "14                     SVM  0.923472  0.923301  0.923472    2:39:40.700000   \n",
       "15                     CNN  0.288649  0.277409  0.288649           2:52:44   \n",
       "16                     DNN  0.286081  0.196078  0.286081           2:52:44   \n",
       "17                     SVM  0.281972  0.199431  0.281972           2:52:44   \n",
       "18                     CNN  0.904468  0.903780  0.904468    0:07:55.180000   \n",
       "19                     DNN  0.933744  0.934022  0.933744    0:07:55.180000   \n",
       "20                     SVM  0.939908  0.940072  0.939908    0:07:55.180000   \n",
       "21                     CNN  0.409348  0.406807  0.409348           0:18:20   \n",
       "22                     DNN  0.511556  0.527785  0.511556           0:18:20   \n",
       "23                     SVM  0.454545  0.463214  0.454545           0:18:20   \n",
       "24                     CNN  0.856703  0.859630  0.856703    0:32:46.600000   \n",
       "25                     DNN  0.901387  0.901441  0.901387    0:32:46.600000   \n",
       "26                     SVM  0.919877  0.919649  0.919877    0:32:46.600000   \n",
       "27                     CNN  0.742681  0.740000  0.742681           1:05:33   \n",
       "28                     DNN  0.829995  0.830627  0.829995           1:05:33   \n",
       "29                     SVM  0.825372  0.825952  0.825372           1:05:33   \n",
       "30                     CNN  0.909091  0.909003  0.909091    0:01:42.750000   \n",
       "31                     DNN  0.916795  0.917043  0.916795    0:01:42.750000   \n",
       "32                     SVM  0.930149  0.930138  0.930149    0:01:42.750000   \n",
       "33                     CNN  0.825886  0.828683  0.825886           0:15:11   \n",
       "34                     DNN  0.896251  0.896160  0.896251           0:15:11   \n",
       "35                     SVM  0.895737  0.895506  0.895737           0:15:11   \n",
       "36                     CNN  0.500770  0.482545  0.500770    0:09:03.000005   \n",
       "37                     DNN  0.714946  0.710270  0.714946    0:09:03.000005   \n",
       "38                     SVM  0.727273  0.724396  0.727273    0:09:03.000005   \n",
       "\n",
       "   time.format.train time.format.evaluate time.format.all  \n",
       "0     0:00:00.015000       0:00:00.024600  0:00:05.755600  \n",
       "1     0:00:00.379000       0:00:00.024000  0:00:06.119000  \n",
       "2     0:00:00.158000       0:00:00.017300  0:00:05.891300  \n",
       "3     0:00:00.044000       0:00:00.063300  0:00:05.173300  \n",
       "4     0:00:00.223000       0:00:00.025900  0:00:05.314900  \n",
       "5     0:00:00.115000       0:00:00.025400  0:00:05.206400  \n",
       "6     0:00:00.012600       0:00:00.025100  0:00:05.644700  \n",
       "7     0:00:00.380000       0:00:00.023400  0:00:06.010400  \n",
       "8     0:00:00.149000       0:00:00.026600  0:00:05.782600  \n",
       "9     0:00:00.041000       0:00:00.063600  0:00:04.961600  \n",
       "10    0:00:00.205000       0:00:00.026200  0:00:05.088200  \n",
       "11    0:00:00.082000       0:00:00.030000  0:00:04.969000  \n",
       "12    0:04:34.402000       0:00:05.820000  2:44:20.922000  \n",
       "13           0:03:06       0:00:04.860000  2:42:51.560000  \n",
       "14    0:00:02.120000       0:00:00.023100  2:39:42.843100  \n",
       "15    0:01:12.448000       0:00:03.590000  2:54:00.038000  \n",
       "16           0:01:12       0:00:01.500000  2:53:57.500000  \n",
       "17    0:00:00.290000       0:00:00.108000  2:52:44.398000  \n",
       "18    0:04:41.409000       0:00:05.830000  0:12:42.419000  \n",
       "19           0:03:00       0:00:04.850000  0:11:00.030000  \n",
       "20    0:00:01.660000       0:00:00.068900  0:07:56.908900  \n",
       "21    0:01:15.392000       0:00:03.320000  0:19:38.712000  \n",
       "22    0:00:58.300000       0:00:01.270000  0:19:19.570000  \n",
       "23    0:00:00.051000       0:00:00.016000  0:18:20.067000  \n",
       "24    0:04:40.397000       0:00:05.720000  0:37:32.717000  \n",
       "25           0:03:06       0:00:04.550000  0:35:57.150000  \n",
       "26    0:00:01.420000       0:00:00.031100  0:32:48.051100  \n",
       "27    0:01:22.426000       0:00:03.470000  1:06:58.896000  \n",
       "28           0:01:12              0:00:09         1:06:54  \n",
       "29    0:00:00.470000       0:00:00.100000  1:05:33.570000  \n",
       "30    0:04:27.397000       0:00:05.740000  0:06:15.887000  \n",
       "31           0:02:56       0:00:04.680000  0:04:43.430000  \n",
       "32    0:00:01.150000       0:00:00.021300  0:01:43.921300  \n",
       "33    0:01:19.388000       0:00:03.280000  0:16:33.668000  \n",
       "34           0:01:01       0:00:01.210000  0:16:13.210000  \n",
       "35    0:00:00.054600       0:00:00.019100  0:15:11.073700  \n",
       "36    0:04:07.422000              0:00:06  0:13:16.422005  \n",
       "37           0:03:01       0:00:04.370000  0:12:08.370005  \n",
       "38    0:00:10.100000       0:00:00.353000  0:09:13.453005  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "\n",
    "csvpath = os.path.join(os.getcwd(), '..', 'data', 'records_CSV', 'trial5_all_22.csv') \n",
    "df = pd.DataFrame.from_csv(csvpath)\n",
    "df_display = df # df['NO' == df['useStopwords']]\n",
    "df_display.reset_index(drop=True, inplace=True)\n",
    "display(df_display)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model.source</th>\n",
       "      <th>useStopwords</th>\n",
       "      <th>tool.word</th>\n",
       "      <th>model.word</th>\n",
       "      <th>model.document</th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro-F1</th>\n",
       "      <th>micro-F1</th>\n",
       "      <th>time.format.all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>TF*IDF-LSA</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.731382</td>\n",
       "      <td>0.733431</td>\n",
       "      <td>0.731382</td>\n",
       "      <td>0:00:05.755600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>TF*IDF-LSA</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.707756</td>\n",
       "      <td>0.707246</td>\n",
       "      <td>0.707756</td>\n",
       "      <td>0:00:06.119000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>TF*IDF-LSA</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.897791</td>\n",
       "      <td>0.898563</td>\n",
       "      <td>0.897791</td>\n",
       "      <td>0:00:05.891300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>TF*IDF-Plain</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.842322</td>\n",
       "      <td>0.840255</td>\n",
       "      <td>0.842322</td>\n",
       "      <td>0:00:05.173300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>TF*IDF-Plain</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.821777</td>\n",
       "      <td>0.823668</td>\n",
       "      <td>0.821777</td>\n",
       "      <td>0:00:05.314900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>TF*IDF-Plain</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.887519</td>\n",
       "      <td>0.888503</td>\n",
       "      <td>0.887519</td>\n",
       "      <td>0:00:05.206400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>corpus</td>\n",
       "      <td>yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>BOW</td>\n",
       "      <td>TF*IDF-LSA</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.781498</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0:00:05.644700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>corpus</td>\n",
       "      <td>yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>BOW</td>\n",
       "      <td>TF*IDF-LSA</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.754494</td>\n",
       "      <td>0.754016</td>\n",
       "      <td>0.754494</td>\n",
       "      <td>0:00:06.010400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>corpus</td>\n",
       "      <td>yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>BOW</td>\n",
       "      <td>TF*IDF-LSA</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.896251</td>\n",
       "      <td>0.897107</td>\n",
       "      <td>0.896251</td>\n",
       "      <td>0:00:05.782600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>corpus</td>\n",
       "      <td>yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>BOW</td>\n",
       "      <td>TF*IDF-Plain</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.843862</td>\n",
       "      <td>0.841737</td>\n",
       "      <td>0.843862</td>\n",
       "      <td>0:00:04.961600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>corpus</td>\n",
       "      <td>yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>BOW</td>\n",
       "      <td>TF*IDF-Plain</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.837699</td>\n",
       "      <td>0.839667</td>\n",
       "      <td>0.837699</td>\n",
       "      <td>0:00:05.088200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>corpus</td>\n",
       "      <td>yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>BOW</td>\n",
       "      <td>TF*IDF-Plain</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.889574</td>\n",
       "      <td>0.890771</td>\n",
       "      <td>0.889574</td>\n",
       "      <td>0:00:04.969000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.864920</td>\n",
       "      <td>0.861901</td>\n",
       "      <td>0.864920</td>\n",
       "      <td>2:44:20.922000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>DNN</td>\n",
       "      <td>0.906523</td>\n",
       "      <td>0.906468</td>\n",
       "      <td>0.906523</td>\n",
       "      <td>2:42:51.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.923472</td>\n",
       "      <td>0.923301</td>\n",
       "      <td>0.923472</td>\n",
       "      <td>2:39:42.843100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>BagOfConcepts-TFIDF</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.288649</td>\n",
       "      <td>0.277409</td>\n",
       "      <td>0.288649</td>\n",
       "      <td>2:54:00.038000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>BagOfConcepts-TFIDF</td>\n",
       "      <td>DNN</td>\n",
       "      <td>0.286081</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.286081</td>\n",
       "      <td>2:53:57.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>BagOfConcepts-TFIDF</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.281972</td>\n",
       "      <td>0.199431</td>\n",
       "      <td>0.281972</td>\n",
       "      <td>2:52:44.398000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.904468</td>\n",
       "      <td>0.903780</td>\n",
       "      <td>0.904468</td>\n",
       "      <td>0:12:42.419000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>DNN</td>\n",
       "      <td>0.933744</td>\n",
       "      <td>0.934022</td>\n",
       "      <td>0.933744</td>\n",
       "      <td>0:11:00.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.939908</td>\n",
       "      <td>0.940072</td>\n",
       "      <td>0.939908</td>\n",
       "      <td>0:07:56.908900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>BagOfConcepts-TFIDF</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.409348</td>\n",
       "      <td>0.406807</td>\n",
       "      <td>0.409348</td>\n",
       "      <td>0:19:38.712000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>BagOfConcepts-TFIDF</td>\n",
       "      <td>DNN</td>\n",
       "      <td>0.511556</td>\n",
       "      <td>0.527785</td>\n",
       "      <td>0.511556</td>\n",
       "      <td>0:19:19.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>BagOfConcepts-TFIDF</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.463214</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0:18:20.067000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.856703</td>\n",
       "      <td>0.859630</td>\n",
       "      <td>0.856703</td>\n",
       "      <td>0:37:32.717000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>DNN</td>\n",
       "      <td>0.901387</td>\n",
       "      <td>0.901441</td>\n",
       "      <td>0.901387</td>\n",
       "      <td>0:35:57.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.919877</td>\n",
       "      <td>0.919649</td>\n",
       "      <td>0.919877</td>\n",
       "      <td>0:32:48.051100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>BagOfConcepts-TFIDF</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.742681</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.742681</td>\n",
       "      <td>1:06:58.896000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>BagOfConcepts-TFIDF</td>\n",
       "      <td>DNN</td>\n",
       "      <td>0.829995</td>\n",
       "      <td>0.830627</td>\n",
       "      <td>0.829995</td>\n",
       "      <td>1:06:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>BagOfConcepts-TFIDF</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.825372</td>\n",
       "      <td>0.825952</td>\n",
       "      <td>0.825372</td>\n",
       "      <td>1:05:33.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909003</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0:06:15.887000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>DNN</td>\n",
       "      <td>0.916795</td>\n",
       "      <td>0.917043</td>\n",
       "      <td>0.916795</td>\n",
       "      <td>0:04:43.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.930149</td>\n",
       "      <td>0.930138</td>\n",
       "      <td>0.930149</td>\n",
       "      <td>0:01:43.921300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>BagOfConcepts-TFIDF</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.825886</td>\n",
       "      <td>0.828683</td>\n",
       "      <td>0.825886</td>\n",
       "      <td>0:16:33.668000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>BagOfConcepts-TFIDF</td>\n",
       "      <td>DNN</td>\n",
       "      <td>0.896251</td>\n",
       "      <td>0.896160</td>\n",
       "      <td>0.896251</td>\n",
       "      <td>0:16:13.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>BagOfConcepts-TFIDF</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.895737</td>\n",
       "      <td>0.895506</td>\n",
       "      <td>0.895737</td>\n",
       "      <td>0:15:11.073700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>NO</td>\n",
       "      <td>Doc2Vec</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.500770</td>\n",
       "      <td>0.482545</td>\n",
       "      <td>0.500770</td>\n",
       "      <td>0:13:16.422005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>NO</td>\n",
       "      <td>Doc2Vec</td>\n",
       "      <td>DNN</td>\n",
       "      <td>0.714946</td>\n",
       "      <td>0.710270</td>\n",
       "      <td>0.714946</td>\n",
       "      <td>0:12:08.370005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>NO</td>\n",
       "      <td>Doc2Vec</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.724396</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0:09:13.453005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model.source useStopwords   tool.word model.word       model.document  \\\n",
       "0        corpus           NO          NO         NO           TF*IDF-LSA   \n",
       "1        corpus           NO          NO         NO           TF*IDF-LSA   \n",
       "2        corpus           NO          NO         NO           TF*IDF-LSA   \n",
       "3        corpus           NO          NO         NO         TF*IDF-Plain   \n",
       "4        corpus           NO          NO         NO         TF*IDF-Plain   \n",
       "5        corpus           NO          NO         NO         TF*IDF-Plain   \n",
       "6        corpus          yes          NO        BOW           TF*IDF-LSA   \n",
       "7        corpus          yes          NO        BOW           TF*IDF-LSA   \n",
       "8        corpus          yes          NO        BOW           TF*IDF-LSA   \n",
       "9        corpus          yes          NO        BOW         TF*IDF-Plain   \n",
       "10       corpus          yes          NO        BOW         TF*IDF-Plain   \n",
       "11       corpus          yes          NO        BOW         TF*IDF-Plain   \n",
       "12        text8           NO  TensorFlow   Word2Vec       ArithmeticMean   \n",
       "13        text8           NO  TensorFlow   Word2Vec       ArithmeticMean   \n",
       "14        text8           NO  TensorFlow   Word2Vec       ArithmeticMean   \n",
       "15        text8           NO  TensorFlow   Word2Vec  BagOfConcepts-TFIDF   \n",
       "16        text8           NO  TensorFlow   Word2Vec  BagOfConcepts-TFIDF   \n",
       "17        text8           NO  TensorFlow   Word2Vec  BagOfConcepts-TFIDF   \n",
       "18       corpus           NO  TensorFlow   Word2Vec       ArithmeticMean   \n",
       "19       corpus           NO  TensorFlow   Word2Vec       ArithmeticMean   \n",
       "20       corpus           NO  TensorFlow   Word2Vec       ArithmeticMean   \n",
       "21       corpus           NO  TensorFlow   Word2Vec  BagOfConcepts-TFIDF   \n",
       "22       corpus           NO  TensorFlow   Word2Vec  BagOfConcepts-TFIDF   \n",
       "23       corpus           NO  TensorFlow   Word2Vec  BagOfConcepts-TFIDF   \n",
       "24        text8           NO      gensim   Word2Vec       ArithmeticMean   \n",
       "25        text8           NO      gensim   Word2Vec       ArithmeticMean   \n",
       "26        text8           NO      gensim   Word2Vec       ArithmeticMean   \n",
       "27        text8           NO      gensim   Word2Vec  BagOfConcepts-TFIDF   \n",
       "28        text8           NO      gensim   Word2Vec  BagOfConcepts-TFIDF   \n",
       "29        text8           NO      gensim   Word2Vec  BagOfConcepts-TFIDF   \n",
       "30       corpus           NO      gensim   Word2Vec       ArithmeticMean   \n",
       "31       corpus           NO      gensim   Word2Vec       ArithmeticMean   \n",
       "32       corpus           NO      gensim   Word2Vec       ArithmeticMean   \n",
       "33       corpus           NO      gensim   Word2Vec  BagOfConcepts-TFIDF   \n",
       "34       corpus           NO      gensim   Word2Vec  BagOfConcepts-TFIDF   \n",
       "35       corpus           NO      gensim   Word2Vec  BagOfConcepts-TFIDF   \n",
       "36       corpus           NO      gensim         NO              Doc2Vec   \n",
       "37       corpus           NO      gensim         NO              Doc2Vec   \n",
       "38       corpus           NO      gensim         NO              Doc2Vec   \n",
       "\n",
       "                classifier  accuracy  macro-F1  micro-F1 time.format.all  \n",
       "0               GaussianNB  0.731382  0.733431  0.731382  0:00:05.755600  \n",
       "1   RandomForestClassifier  0.707756  0.707246  0.707756  0:00:06.119000  \n",
       "2                      SVM  0.897791  0.898563  0.897791  0:00:05.891300  \n",
       "3               GaussianNB  0.842322  0.840255  0.842322  0:00:05.173300  \n",
       "4   RandomForestClassifier  0.821777  0.823668  0.821777  0:00:05.314900  \n",
       "5                      SVM  0.887519  0.888503  0.887519  0:00:05.206400  \n",
       "6               GaussianNB  0.779661  0.781498  0.779661  0:00:05.644700  \n",
       "7   RandomForestClassifier  0.754494  0.754016  0.754494  0:00:06.010400  \n",
       "8                      SVM  0.896251  0.897107  0.896251  0:00:05.782600  \n",
       "9               GaussianNB  0.843862  0.841737  0.843862  0:00:04.961600  \n",
       "10  RandomForestClassifier  0.837699  0.839667  0.837699  0:00:05.088200  \n",
       "11                     SVM  0.889574  0.890771  0.889574  0:00:04.969000  \n",
       "12                     CNN  0.864920  0.861901  0.864920  2:44:20.922000  \n",
       "13                     DNN  0.906523  0.906468  0.906523  2:42:51.560000  \n",
       "14                     SVM  0.923472  0.923301  0.923472  2:39:42.843100  \n",
       "15                     CNN  0.288649  0.277409  0.288649  2:54:00.038000  \n",
       "16                     DNN  0.286081  0.196078  0.286081  2:53:57.500000  \n",
       "17                     SVM  0.281972  0.199431  0.281972  2:52:44.398000  \n",
       "18                     CNN  0.904468  0.903780  0.904468  0:12:42.419000  \n",
       "19                     DNN  0.933744  0.934022  0.933744  0:11:00.030000  \n",
       "20                     SVM  0.939908  0.940072  0.939908  0:07:56.908900  \n",
       "21                     CNN  0.409348  0.406807  0.409348  0:19:38.712000  \n",
       "22                     DNN  0.511556  0.527785  0.511556  0:19:19.570000  \n",
       "23                     SVM  0.454545  0.463214  0.454545  0:18:20.067000  \n",
       "24                     CNN  0.856703  0.859630  0.856703  0:37:32.717000  \n",
       "25                     DNN  0.901387  0.901441  0.901387  0:35:57.150000  \n",
       "26                     SVM  0.919877  0.919649  0.919877  0:32:48.051100  \n",
       "27                     CNN  0.742681  0.740000  0.742681  1:06:58.896000  \n",
       "28                     DNN  0.829995  0.830627  0.829995         1:06:54  \n",
       "29                     SVM  0.825372  0.825952  0.825372  1:05:33.570000  \n",
       "30                     CNN  0.909091  0.909003  0.909091  0:06:15.887000  \n",
       "31                     DNN  0.916795  0.917043  0.916795  0:04:43.430000  \n",
       "32                     SVM  0.930149  0.930138  0.930149  0:01:43.921300  \n",
       "33                     CNN  0.825886  0.828683  0.825886  0:16:33.668000  \n",
       "34                     DNN  0.896251  0.896160  0.896251  0:16:13.210000  \n",
       "35                     SVM  0.895737  0.895506  0.895737  0:15:11.073700  \n",
       "36                     CNN  0.500770  0.482545  0.500770  0:13:16.422005  \n",
       "37                     DNN  0.714946  0.710270  0.714946  0:12:08.370005  \n",
       "38                     SVM  0.727273  0.724396  0.727273  0:09:13.453005  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_display.drop(['time.format.model', 'time.format.train', 'time.format.evaluate'], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 以 `macro-F1` 为指标，筛选出超过 0.8 的组合（考虑到 `marco-F1` 与 `micro-F1` 在此处实际差别不大）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model.source</th>\n",
       "      <th>useStopwords</th>\n",
       "      <th>tool.word</th>\n",
       "      <th>model.word</th>\n",
       "      <th>model.document</th>\n",
       "      <th>classifier</th>\n",
       "      <th>macro-F1</th>\n",
       "      <th>micro-F1</th>\n",
       "      <th>time.format.all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.940072</td>\n",
       "      <td>0.939908</td>\n",
       "      <td>0:07:56.908900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>DNN</td>\n",
       "      <td>0.934022</td>\n",
       "      <td>0.933744</td>\n",
       "      <td>0:11:00.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.930138</td>\n",
       "      <td>0.930149</td>\n",
       "      <td>0:01:43.921300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.923301</td>\n",
       "      <td>0.923472</td>\n",
       "      <td>2:39:42.843100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.919649</td>\n",
       "      <td>0.919877</td>\n",
       "      <td>0:32:48.051100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>DNN</td>\n",
       "      <td>0.917043</td>\n",
       "      <td>0.916795</td>\n",
       "      <td>0:04:43.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.909003</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0:06:15.887000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>DNN</td>\n",
       "      <td>0.906468</td>\n",
       "      <td>0.906523</td>\n",
       "      <td>2:42:51.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.903780</td>\n",
       "      <td>0.904468</td>\n",
       "      <td>0:12:42.419000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>DNN</td>\n",
       "      <td>0.901441</td>\n",
       "      <td>0.901387</td>\n",
       "      <td>0:35:57.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>TF*IDF-LSA</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.898563</td>\n",
       "      <td>0.897791</td>\n",
       "      <td>0:00:05.891300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>corpus</td>\n",
       "      <td>yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>BOW</td>\n",
       "      <td>TF*IDF-LSA</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.897107</td>\n",
       "      <td>0.896251</td>\n",
       "      <td>0:00:05.782600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>BagOfConcepts-TFIDF</td>\n",
       "      <td>DNN</td>\n",
       "      <td>0.896160</td>\n",
       "      <td>0.896251</td>\n",
       "      <td>0:16:13.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>BagOfConcepts-TFIDF</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.895506</td>\n",
       "      <td>0.895737</td>\n",
       "      <td>0:15:11.073700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>corpus</td>\n",
       "      <td>yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>BOW</td>\n",
       "      <td>TF*IDF-Plain</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.890771</td>\n",
       "      <td>0.889574</td>\n",
       "      <td>0:00:04.969000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>TF*IDF-Plain</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.888503</td>\n",
       "      <td>0.887519</td>\n",
       "      <td>0:00:05.206400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.861901</td>\n",
       "      <td>0.864920</td>\n",
       "      <td>2:44:20.922000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>ArithmeticMean</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.859630</td>\n",
       "      <td>0.856703</td>\n",
       "      <td>0:37:32.717000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>corpus</td>\n",
       "      <td>yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>BOW</td>\n",
       "      <td>TF*IDF-Plain</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.841737</td>\n",
       "      <td>0.843862</td>\n",
       "      <td>0:00:04.961600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>TF*IDF-Plain</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.840255</td>\n",
       "      <td>0.842322</td>\n",
       "      <td>0:00:05.173300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>corpus</td>\n",
       "      <td>yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>BOW</td>\n",
       "      <td>TF*IDF-Plain</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.839667</td>\n",
       "      <td>0.837699</td>\n",
       "      <td>0:00:05.088200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>BagOfConcepts-TFIDF</td>\n",
       "      <td>DNN</td>\n",
       "      <td>0.830627</td>\n",
       "      <td>0.829995</td>\n",
       "      <td>1:06:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>BagOfConcepts-TFIDF</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.828683</td>\n",
       "      <td>0.825886</td>\n",
       "      <td>0:16:33.668000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>text8</td>\n",
       "      <td>NO</td>\n",
       "      <td>gensim</td>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>BagOfConcepts-TFIDF</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.825952</td>\n",
       "      <td>0.825372</td>\n",
       "      <td>1:05:33.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corpus</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>TF*IDF-Plain</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.823668</td>\n",
       "      <td>0.821777</td>\n",
       "      <td>0:00:05.314900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model.source useStopwords   tool.word model.word       model.document  \\\n",
       "20       corpus           NO  TensorFlow   Word2Vec       ArithmeticMean   \n",
       "19       corpus           NO  TensorFlow   Word2Vec       ArithmeticMean   \n",
       "32       corpus           NO      gensim   Word2Vec       ArithmeticMean   \n",
       "14        text8           NO  TensorFlow   Word2Vec       ArithmeticMean   \n",
       "26        text8           NO      gensim   Word2Vec       ArithmeticMean   \n",
       "31       corpus           NO      gensim   Word2Vec       ArithmeticMean   \n",
       "30       corpus           NO      gensim   Word2Vec       ArithmeticMean   \n",
       "13        text8           NO  TensorFlow   Word2Vec       ArithmeticMean   \n",
       "18       corpus           NO  TensorFlow   Word2Vec       ArithmeticMean   \n",
       "25        text8           NO      gensim   Word2Vec       ArithmeticMean   \n",
       "2        corpus           NO          NO         NO           TF*IDF-LSA   \n",
       "8        corpus          yes          NO        BOW           TF*IDF-LSA   \n",
       "34       corpus           NO      gensim   Word2Vec  BagOfConcepts-TFIDF   \n",
       "35       corpus           NO      gensim   Word2Vec  BagOfConcepts-TFIDF   \n",
       "11       corpus          yes          NO        BOW         TF*IDF-Plain   \n",
       "5        corpus           NO          NO         NO         TF*IDF-Plain   \n",
       "12        text8           NO  TensorFlow   Word2Vec       ArithmeticMean   \n",
       "24        text8           NO      gensim   Word2Vec       ArithmeticMean   \n",
       "9        corpus          yes          NO        BOW         TF*IDF-Plain   \n",
       "3        corpus           NO          NO         NO         TF*IDF-Plain   \n",
       "10       corpus          yes          NO        BOW         TF*IDF-Plain   \n",
       "28        text8           NO      gensim   Word2Vec  BagOfConcepts-TFIDF   \n",
       "33       corpus           NO      gensim   Word2Vec  BagOfConcepts-TFIDF   \n",
       "29        text8           NO      gensim   Word2Vec  BagOfConcepts-TFIDF   \n",
       "4        corpus           NO          NO         NO         TF*IDF-Plain   \n",
       "\n",
       "                classifier  macro-F1  micro-F1 time.format.all  \n",
       "20                     SVM  0.940072  0.939908  0:07:56.908900  \n",
       "19                     DNN  0.934022  0.933744  0:11:00.030000  \n",
       "32                     SVM  0.930138  0.930149  0:01:43.921300  \n",
       "14                     SVM  0.923301  0.923472  2:39:42.843100  \n",
       "26                     SVM  0.919649  0.919877  0:32:48.051100  \n",
       "31                     DNN  0.917043  0.916795  0:04:43.430000  \n",
       "30                     CNN  0.909003  0.909091  0:06:15.887000  \n",
       "13                     DNN  0.906468  0.906523  2:42:51.560000  \n",
       "18                     CNN  0.903780  0.904468  0:12:42.419000  \n",
       "25                     DNN  0.901441  0.901387  0:35:57.150000  \n",
       "2                      SVM  0.898563  0.897791  0:00:05.891300  \n",
       "8                      SVM  0.897107  0.896251  0:00:05.782600  \n",
       "34                     DNN  0.896160  0.896251  0:16:13.210000  \n",
       "35                     SVM  0.895506  0.895737  0:15:11.073700  \n",
       "11                     SVM  0.890771  0.889574  0:00:04.969000  \n",
       "5                      SVM  0.888503  0.887519  0:00:05.206400  \n",
       "12                     CNN  0.861901  0.864920  2:44:20.922000  \n",
       "24                     CNN  0.859630  0.856703  0:37:32.717000  \n",
       "9               GaussianNB  0.841737  0.843862  0:00:04.961600  \n",
       "3               GaussianNB  0.840255  0.842322  0:00:05.173300  \n",
       "10  RandomForestClassifier  0.839667  0.837699  0:00:05.088200  \n",
       "28                     DNN  0.830627  0.829995         1:06:54  \n",
       "33                     CNN  0.828683  0.825886  0:16:33.668000  \n",
       "29                     SVM  0.825952  0.825372  1:05:33.570000  \n",
       "4   RandomForestClassifier  0.823668  0.821777  0:00:05.314900  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_pick = df_display.sort_values(\n",
    "        by=['macro-F1'], ascending=[False]\n",
    "#         by=['time.format.all'], ascending=[True]\n",
    "    ).drop(\n",
    "        [\n",
    "            'accuracy', 'time.format.model', 'time.format.train', 'time.format.evaluate' #'useStopwords', \n",
    "        ], axis=1\n",
    "    )\n",
    "\n",
    "df_base80 = df_pick[df_pick['macro-F1'] > 0.80]\n",
    "\n",
    "display(df_base80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 在上述超过 0.8 的组合中，对每个组合变量下的每个独特值对应项目（如对 `model.word` 下的 `Word2Vec` 和 `BOW`），在原始实验记录中的比例、在上述超过 0.8 的记录中的比例、以及比例的变化（是否上升，上升多少），从而考察每一个变量的变化对实验结果的影响"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 之所以这样统计，是特别考虑到了以 `model.word` 为代表的样本数目不平衡：在所有 48 组数据中，`BOW` 项只有 9 组，`Doc2Vec` 只有 3 组，剩下的 36 组全是 `Word2Vec`。这时，必须考察这些项在记录中的**比例变化**，更能反映出变量中值的选择对实验的影响。\n",
    "> \n",
    "> 举例：`BOW` 在原始记录中占 9 / 48 = 0.1875，`Word2Vec` 占 36 / 48 = 0.75。若在筛选记录（`marco-F1` > 0.8）中，`BOW` 所占比例仍为 0.1875，`Word2Vec` 仍占 0.75，说明是否选择词嵌入模型，对 `marco-F1` > 0.8 是否成立并不造成影响，换句话说两种模型一样稳定；若 `Word2Vec`所占比例上升、且比 `BOW` 上升得多，说明选择词嵌入模型会（比不用词嵌入模型而直接使用词袋表示文本）使分类系统的分类效果更好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>raw</th>\n",
       "      <th>base80</th>\n",
       "      <th>isRise</th>\n",
       "      <th>riseRelatively</th>\n",
       "      <th>timeAverage_base80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>corpus</th>\n",
       "      <td>model.source</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.68</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.017778</td>\n",
       "      <td>0:05:28.407953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text8</th>\n",
       "      <td>model.source</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.32</td>\n",
       "      <td>True</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1:30:42.601650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO</th>\n",
       "      <td>useStopwords</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.84</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.007273</td>\n",
       "      <td>0:38:58.235571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>useStopwords</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.16</td>\n",
       "      <td>True</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0:00:05.200350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TensorFlow</th>\n",
       "      <td>tool.word</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.24</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.220000</td>\n",
       "      <td>1:26:25.780500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gensim</th>\n",
       "      <td>tool.word</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.44</td>\n",
       "      <td>True</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>0:27:13.334373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO</th>\n",
       "      <td>tool.word</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.32</td>\n",
       "      <td>True</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0:00:05.298413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word2Vec</th>\n",
       "      <td>model.word</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.68</td>\n",
       "      <td>True</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0:48:07.138888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO</th>\n",
       "      <td>model.word</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.16</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.306667</td>\n",
       "      <td>0:00:05.396475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOW</th>\n",
       "      <td>model.word</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.16</td>\n",
       "      <td>True</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0:00:05.200350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ArithmeticMean</th>\n",
       "      <td>model.document</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.48</td>\n",
       "      <td>True</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0:53:07.986617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF*IDF-LSA</th>\n",
       "      <td>model.document</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.08</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.480000</td>\n",
       "      <td>0:00:05.836950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BagOfConcepts-TFIDF</th>\n",
       "      <td>model.document</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.20</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>0:36:05.104340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF*IDF-Plain</th>\n",
       "      <td>model.document</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.24</td>\n",
       "      <td>True</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0:00:05.118900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>classifier</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.40</td>\n",
       "      <td>True</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0:28:19.821740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNN</th>\n",
       "      <td>classifier</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.24</td>\n",
       "      <td>True</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0:49:36.563333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>classifier</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.20</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0:47:29.122600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>classifier</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.08</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.220000</td>\n",
       "      <td>0:00:05.067450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>classifier</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.08</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.220000</td>\n",
       "      <td>0:00:05.201550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                column       raw  base80  isRise  \\\n",
       "corpus                    model.source  0.692308    0.68   False   \n",
       "text8                     model.source  0.307692    0.32    True   \n",
       "NO                        useStopwords  0.846154    0.84   False   \n",
       "yes                       useStopwords  0.153846    0.16    True   \n",
       "TensorFlow                   tool.word  0.307692    0.24   False   \n",
       "gensim                       tool.word  0.384615    0.44    True   \n",
       "NO                           tool.word  0.307692    0.32    True   \n",
       "Word2Vec                    model.word  0.615385    0.68    True   \n",
       "NO                          model.word  0.230769    0.16   False   \n",
       "BOW                         model.word  0.153846    0.16    True   \n",
       "ArithmeticMean          model.document  0.307692    0.48    True   \n",
       "TF*IDF-LSA              model.document  0.153846    0.08   False   \n",
       "BagOfConcepts-TFIDF     model.document  0.307692    0.20   False   \n",
       "TF*IDF-Plain            model.document  0.153846    0.24    True   \n",
       "SVM                         classifier  0.333333    0.40    True   \n",
       "DNN                         classifier  0.230769    0.24    True   \n",
       "CNN                         classifier  0.230769    0.20   False   \n",
       "GaussianNB                  classifier  0.102564    0.08   False   \n",
       "RandomForestClassifier      classifier  0.102564    0.08   False   \n",
       "\n",
       "                        riseRelatively timeAverage_base80  \n",
       "corpus                       -0.017778     0:05:28.407953  \n",
       "text8                         0.040000     1:30:42.601650  \n",
       "NO                           -0.007273     0:38:58.235571  \n",
       "yes                           0.040000     0:00:05.200350  \n",
       "TensorFlow                   -0.220000     1:26:25.780500  \n",
       "gensim                        0.144000     0:27:13.334373  \n",
       "NO                            0.040000     0:00:05.298413  \n",
       "Word2Vec                      0.105000     0:48:07.138888  \n",
       "NO                           -0.306667     0:00:05.396475  \n",
       "BOW                           0.040000     0:00:05.200350  \n",
       "ArithmeticMean                0.560000     0:53:07.986617  \n",
       "TF*IDF-LSA                   -0.480000     0:00:05.836950  \n",
       "BagOfConcepts-TFIDF          -0.350000     0:36:05.104340  \n",
       "TF*IDF-Plain                  0.560000     0:00:05.118900  \n",
       "SVM                           0.200000     0:28:19.821740  \n",
       "DNN                           0.040000     0:49:36.563333  \n",
       "CNN                          -0.133333     0:47:29.122600  \n",
       "GaussianNB                   -0.220000     0:00:05.067450  \n",
       "RandomForestClassifier       -0.220000     0:00:05.201550  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmpdict = {}\n",
    "indLabels = []\n",
    "colLabels = ['column', 'raw', 'base80', 'isRise', 'riseRelatively', 'timeAverage_base80']\n",
    "\n",
    "for rawOrNot in colLabels:\n",
    "    tmpdict[rawOrNot] = []\n",
    "    \n",
    "for col in df_base80.columns:\n",
    "    if col not in ['macro-F1', 'micro-F1', 'time.format.all']:\n",
    "        for item in df_base80[col].unique():\n",
    "            indLabels += [item]\n",
    "            tmpdict['column'].append(col)\n",
    "            tmpdict['raw'].append(df_display[item == df_display[col]].count()[0] / float(df_display.count()[0]))\n",
    "            tmpdict['base80'].append(df_base80[item == df_base80[col]].count()[0] / float(df_base80.count()[0]))\n",
    "            tmpdict['isRise'].append(tmpdict['base80'][-1] > tmpdict['raw'][-1])\n",
    "            tmpdict['riseRelatively'].append((tmpdict['base80'][-1] - tmpdict['raw'][-1])/tmpdict['raw'][-1])\n",
    "\n",
    "            tmpt = np.array([0., 0., 0.])\n",
    "            for i in df_base80[item == df_base80[col]]['time.format.all']:\n",
    "                newi = np.array([float(j) for j in i.split(':')])\n",
    "                tmpt = tmpt + newi\n",
    "            tmpct = df_base80[item == df_base80[col]]['time.format.all'].count()\n",
    "            tmpt = [tmpi/tmpct for tmpi in tmpt]\n",
    "            tobj = str(datetime.timedelta(seconds=tmpt[2], minutes=tmpt[1], hours=tmpt[0]))\n",
    "\n",
    "            tmpdict['timeAverage_base80'].append(tobj)\n",
    "\n",
    "# print(indLabels)\n",
    "# for i in tmpdict:\n",
    "#     print('lenth of {}: {}'.format(i, len(tmpdict[i])))\n",
    "#     print(tmpdict[i])\n",
    "    \n",
    "df_base80_indication = pd.DataFrame(data=tmpdict, index=indLabels, columns=colLabels)\n",
    "display(df_base80_indication)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 分项目考察比例变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record for model.source in DataFrame(>80%):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>raw</th>\n",
       "      <th>base80</th>\n",
       "      <th>isRise</th>\n",
       "      <th>riseRelatively</th>\n",
       "      <th>timeAverage_base80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>corpus</th>\n",
       "      <td>model.source</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.68</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.017778</td>\n",
       "      <td>0:05:28.407953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text8</th>\n",
       "      <td>model.source</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.32</td>\n",
       "      <td>True</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1:30:42.601650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              column       raw  base80  isRise  riseRelatively  \\\n",
       "corpus  model.source  0.692308    0.68   False       -0.017778   \n",
       "text8   model.source  0.307692    0.32    True        0.040000   \n",
       "\n",
       "       timeAverage_base80  \n",
       "corpus     0:05:28.407953  \n",
       "text8      1:30:42.601650  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "Record for useStopwords in DataFrame(>80%):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>raw</th>\n",
       "      <th>base80</th>\n",
       "      <th>isRise</th>\n",
       "      <th>riseRelatively</th>\n",
       "      <th>timeAverage_base80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NO</th>\n",
       "      <td>useStopwords</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.84</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.007273</td>\n",
       "      <td>0:38:58.235571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>useStopwords</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.16</td>\n",
       "      <td>True</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0:00:05.200350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           column       raw  base80  isRise  riseRelatively timeAverage_base80\n",
       "NO   useStopwords  0.846154    0.84   False       -0.007273     0:38:58.235571\n",
       "yes  useStopwords  0.153846    0.16    True        0.040000     0:00:05.200350"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "Record for tool.word in DataFrame(>80%):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>raw</th>\n",
       "      <th>base80</th>\n",
       "      <th>isRise</th>\n",
       "      <th>riseRelatively</th>\n",
       "      <th>timeAverage_base80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TensorFlow</th>\n",
       "      <td>tool.word</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.24</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>1:26:25.780500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gensim</th>\n",
       "      <td>tool.word</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.44</td>\n",
       "      <td>True</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0:27:13.334373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO</th>\n",
       "      <td>tool.word</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.32</td>\n",
       "      <td>True</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0:00:05.298413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               column       raw  base80  isRise  riseRelatively  \\\n",
       "TensorFlow  tool.word  0.307692    0.24   False          -0.220   \n",
       "gensim      tool.word  0.384615    0.44    True           0.144   \n",
       "NO          tool.word  0.307692    0.32    True           0.040   \n",
       "\n",
       "           timeAverage_base80  \n",
       "TensorFlow     1:26:25.780500  \n",
       "gensim         0:27:13.334373  \n",
       "NO             0:00:05.298413  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "Record for model.word in DataFrame(>80%):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>raw</th>\n",
       "      <th>base80</th>\n",
       "      <th>isRise</th>\n",
       "      <th>riseRelatively</th>\n",
       "      <th>timeAverage_base80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Word2Vec</th>\n",
       "      <td>model.word</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.68</td>\n",
       "      <td>True</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0:48:07.138888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO</th>\n",
       "      <td>model.word</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.16</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.306667</td>\n",
       "      <td>0:00:05.396475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOW</th>\n",
       "      <td>model.word</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.16</td>\n",
       "      <td>True</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0:00:05.200350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              column       raw  base80  isRise  riseRelatively  \\\n",
       "Word2Vec  model.word  0.615385    0.68    True        0.105000   \n",
       "NO        model.word  0.230769    0.16   False       -0.306667   \n",
       "BOW       model.word  0.153846    0.16    True        0.040000   \n",
       "\n",
       "         timeAverage_base80  \n",
       "Word2Vec     0:48:07.138888  \n",
       "NO           0:00:05.396475  \n",
       "BOW          0:00:05.200350  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "Record for model.document in DataFrame(>80%):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>raw</th>\n",
       "      <th>base80</th>\n",
       "      <th>isRise</th>\n",
       "      <th>riseRelatively</th>\n",
       "      <th>timeAverage_base80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ArithmeticMean</th>\n",
       "      <td>model.document</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.48</td>\n",
       "      <td>True</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0:53:07.986617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF*IDF-LSA</th>\n",
       "      <td>model.document</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.08</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>0:00:05.836950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BagOfConcepts-TFIDF</th>\n",
       "      <td>model.document</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.20</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0:36:05.104340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF*IDF-Plain</th>\n",
       "      <td>model.document</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.24</td>\n",
       "      <td>True</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0:00:05.118900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             column       raw  base80  isRise  riseRelatively  \\\n",
       "ArithmeticMean       model.document  0.307692    0.48    True            0.56   \n",
       "TF*IDF-LSA           model.document  0.153846    0.08   False           -0.48   \n",
       "BagOfConcepts-TFIDF  model.document  0.307692    0.20   False           -0.35   \n",
       "TF*IDF-Plain         model.document  0.153846    0.24    True            0.56   \n",
       "\n",
       "                    timeAverage_base80  \n",
       "ArithmeticMean          0:53:07.986617  \n",
       "TF*IDF-LSA              0:00:05.836950  \n",
       "BagOfConcepts-TFIDF     0:36:05.104340  \n",
       "TF*IDF-Plain            0:00:05.118900  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "Record for classifier in DataFrame(>80%):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>raw</th>\n",
       "      <th>base80</th>\n",
       "      <th>isRise</th>\n",
       "      <th>riseRelatively</th>\n",
       "      <th>timeAverage_base80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>classifier</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.40</td>\n",
       "      <td>True</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0:28:19.821740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNN</th>\n",
       "      <td>classifier</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.24</td>\n",
       "      <td>True</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0:49:36.563333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>classifier</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.20</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0:47:29.122600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>classifier</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.08</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.220000</td>\n",
       "      <td>0:00:05.067450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>classifier</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.08</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.220000</td>\n",
       "      <td>0:00:05.201550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            column       raw  base80  isRise  riseRelatively  \\\n",
       "SVM                     classifier  0.333333    0.40    True        0.200000   \n",
       "DNN                     classifier  0.230769    0.24    True        0.040000   \n",
       "CNN                     classifier  0.230769    0.20   False       -0.133333   \n",
       "GaussianNB              classifier  0.102564    0.08   False       -0.220000   \n",
       "RandomForestClassifier  classifier  0.102564    0.08   False       -0.220000   \n",
       "\n",
       "                       timeAverage_base80  \n",
       "SVM                        0:28:19.821740  \n",
       "DNN                        0:49:36.563333  \n",
       "CNN                        0:47:29.122600  \n",
       "GaussianNB                 0:00:05.067450  \n",
       "RandomForestClassifier     0:00:05.201550  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n"
     ]
    }
   ],
   "source": [
    "for i in df_base80_indication['column'].unique():\n",
    "    print('Record for {} in DataFrame(>80%):'.format(i))\n",
    "    display(df_base80_indication[i == df_base80_indication['column']])\n",
    "    print('-----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 查看上述数据，得出结论：\n",
    "\n",
    "# 项目 | 结论\n",
    "# -----|---------------\n",
    "# `model.source` | 选择 `corpus` 会比选择` text8` 效果更好。改善效果主要体现在**时间**上，差别显著；比例上也更优，但差别不大。\n",
    "# `tool.word` | 选择使用 `gensim` 建模，效果更好。改善效果主要体现在**时间**上，差别显著；比例上也更优。\n",
    "# `model.word` | 若仅考虑分类的 `macro-F1`，选择词嵌入模型中的 `Word2Vec` 为词汇建模更好；若还要考虑训练时间，则应考虑 `BOW` 模型\n",
    "# `model.document` | 选择使用基于词袋模型的`TF*IDF` 方法，效果最好（单看分类的 `macro-F1`，基于词嵌入模型的词向量均值法（`ArithmeticMean`）也不相上下，但耗时更多）\n",
    "# `classifier` | 选择 `DNN` 作为分类器，效果最好；选择 `SVM` 作为分类器，效果次之，但耗时较少。（注意：该表格其实不甚严谨，因为 SVM 其实参与了基于传统词袋模型的分类器训练，也参与了基于词嵌入模型的分类器训练）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据基准（benchmark）的定义，应该是一个最终训练结果的底线，所以应该根据上述分析结果，尽可能在各变量中选择那些让结果尽可能差的值，在此状况下训练 20 分类的分类器，得到的模型/结果即为基准模型/结果。\n",
    "\n",
    "结合上述各表结果，首先考虑到：由于是基准模型，不希望在上面投入过多计算时间与资源，希望快速得出基准。要满足 2 个条件：\n",
    "\n",
    "1. 耗时较少\n",
    "2. 分类效果较差\n",
    "\n",
    "因此，选择基于 `BOW` 的 `TF*IDF-LSA` 模型显然是创建基准的最佳选择（耗时少；按 `macro-F1` 计，效果相对较差）。\n",
    "\n",
    "在此基础上，选择 `GaussianNB` 或者 `RandomForestClassifier` 差别似乎并不明显。因此将在这两种分类器上都进行建模，选取其中效果更差的那种作为基准。\n",
    "\n",
    "另外，为了初步验证这样得到的模型、结果属于基准，还将选取若干组合进行训练，查看这些组合的分类效果是否比基准好：若比基准好，说明得到的基准是可用的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 以传统算法中的 SVM 为分类器为例，比较 3 类表示模型对结果的影响（词袋表示、词嵌入表示、文档嵌入表示）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次小试训练了在不同文本表示模型上的 5 种分类器，包括 3 种传统分类器（支持向量机 SVM，高斯朴素贝叶斯分类器 GaussianNB，随机森林分类器 RandomForest）与 2 种神经网络分类器（深度神经网络 DNN，卷积神经网络 CNN）。各种分类器在不同文本表示模型上的训练结果如下列各表格所示，小结如下：\n",
    "\n",
    "#### 5.1.1 对于同种分类器，不同表示模型会对训练结果造成影响\n",
    "\n",
    "+ 从**训练效果**上看：\n",
    "    - 查看标准差（`std`）：\n",
    "        * CNN 受文本表示模型的影响最小，GaussianNB 受文本表示模型的影响最大。\n",
    "            - 该结论的成立依赖于忽略下述事实：神经网络分类器仅在 2 种文本表示模型（两种词嵌入模型，即：基于 text8 训练的词向量均值表示；基于待学习语料训练的词向量均值表示）下进行训练，而传统分类器在 5 种文本表示模型（BOW+TFIDF 的直接表示，BOW+TFIDF+LSA，BOW+TFIDF+LDA，以及上述两种词嵌入模型）\n",
    "        * 若考虑上述事实（传统算法在更多的文本表示模型上进行训练，因而变化的可能性更大），则\n",
    "            - 传统分类器中：SVM 受文本表示模型的影响最小，GaussianNB 受文本表示模型的影响最大\n",
    "            - 神经网络分类器种：CNN 比 DNN 受文本表示模型的影响更小\n",
    "            \n",
    "。。。待续"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 对同一种分类器，使用 Word2Vec 作为词嵌入模型表示文本，比较不同训练工具对结果的影响（gensim、TensorFlow）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3  对同一种分类器，使用 Word2Vec 作为词嵌入模型表示文本，比较用于建立词嵌入模型的不同训练语料对结果的影响（corpus、text8）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 综合来看，「表示模型（传统模型/词嵌入模型、训练工具、训练语料） + 分类器」组合的效果评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> + 挑选 2 类表示模型，每类表示模型中挑选出 2 种分类器，共计 4 种「表示模型 + 分类器」的组合，将用于最终的 20 分类任务\n",
    "> + 若选择了 Word2Vec，从 gensim 与 TensorFlow 中挑选出一种来建立词嵌入向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 展望"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 可以（对每种表示模型训练器）实现实现一种类似 [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) 的模块，从而用于从「表示器 + 分类器」的组合种进行自动评分从而进行参数筛选\n",
    "2. 或许可以尝试使用 RNN 来完成分类\n",
    "3. 。。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
