{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -2. 更新日志\n",
    "\n",
    "+ 【2017/05/11】\n",
    "    - 重新梳理前期实验结果，并整合到该份报告中\n",
    "    - 前期实验报告参见同一目录下的其他以 `trial_` 开头的 `.ipynb` 文件\n",
    "+ 【2017/05/21】\n",
    "    - 完成最后一份与词嵌入（word embeding）模型有关的文本表示模型试验，正式开始整合\n",
    "        * 对应的试验文件名为：`gensim-corpus-WordClustering-DataRecordWrapper.ipynb`\n",
    "+ 【2017/05/23】\n",
    "    - 删除本 notebook 中所有代码模块，准备利用 Jupyter Notebook 的 magic commd `%%run jupyter_notebook.ipynb` 进行模块化，从而使该记录本更干净\n",
    "    - 修改第 5 节【5. 总结】部分的结构\n",
    "+ 【2017/05/26】\n",
    "    - 删除 GloVe 计划，重新整理笔记本规划"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -1. 备注\n",
    "\n",
    "1. 搜索该符号以定位到报告中待完善的部分：。。。\n",
    "2. 。。。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 参考文献\n",
    "\n",
    "1. (#miscellaneous) [20 Newsgroup Document Classification Report](http://cn-static.udacity.com/mlnd/Capstone_Poject_Sample01.pdf)\n",
    "2. (#word2vec, #tensorflow) [Vector Representations of Words](https://www.tensorflow.org/tutorials/word2vec)\n",
    "3. (#word2vec) [Distributed Representations of Words and Phrases and their Compositionality](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)\n",
    "4. (#word2vec, #gensim) [models.word2vec – Deep learning with word2vec](https://radimrehurek.com/gensim/models/word2vec.html)\n",
    "5. (#CNN, #tensorflow) [Deep MNIST for Experts](https://www.tensorflow.org/get_started/mnist/pros)\n",
    "6. (#text8) [text8](http://mattmahoney.net/dc/textdata)\n",
    "7. (#tricks) [[译]27 个Jupyter Notebook的小提示与技巧](http://liuchengxu.org/pelican-blog/jupyter-notebook-tips.html)\n",
    "8. 。。。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 实验模块规划\n",
    "\n",
    "粗略规划如下，稍后精细整理：实现下述共计 15 种「表示 + 训练」组合\n",
    "\n",
    "词汇模型 | 文档表示模型 | 分类器训练法\n",
    "---------------|---------------------|---------------------\n",
    "BOW              | TFIDF | SVM\n",
    "                     | TFIDF | NB(Gaussian NB)\n",
    "                     | TFIDF | RF\n",
    "                     | TFIDF-LSA | SVM\n",
    "                     | TFIDF-LSA | NB(Gaussian NB)\n",
    "                     | TFIDF-LSA | RF\n",
    "                     | TFIDF-LDA | SVM\n",
    "                     | TFIDF-LDA | NB(Gaussian NB)\n",
    "                     | TFIDF-LDA | RF\n",
    "Word2Vec      | arithmatic mean representation | SVM\n",
    "                     | arithmatic mean representation | DNN\n",
    "                     | arithmatic mean representation | CNN\n",
    "                     | word-clustering (pure count) | SVM\n",
    "                     | word-clustering (pure count) | DNN\n",
    "                     | word-clustering (pure count) | CNN\n",
    "                     | word-clustering (TF\\*IDF) | SVM\n",
    "                     | word-clustering (TF\\*IDF) | DNN\n",
    "                     | word-clustering (TF\\*IDF) | CNN\n",
    "None             | Doc2Vec | SVM\n",
    "                    | Doc2Vec | DNN\n",
    "                    | Doc2Vec | CNN\n",
    "\n",
    "其中：\n",
    "+ 名词解释\n",
    "    - 词汇表示模型\n",
    "        * BOW：Bag-of-Words，词袋模型\n",
    "        * TF-IDF：Term Frequency - Inverse Document Frequency，文档-逆文档频率，其中\n",
    "            - TF：词频，指该[词汇在文档中出现的原始频数](http://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting)\n",
    "            - IDF：逆文档频率，指 $idf(d, t) = log( \\frac{n}{df(d, t)} ) + 1$（该公式为 sklearn 中对 $idf(d, t)$的[实现](https://github.com/scikit-learn/scikit-learn/blob/14031f6/sklearn/feature_extraction/text.py#L1017)），其中 $df(d, t)$ 为[包含词汇 $t$ 的文档 $d$ 数目](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer)\n",
    "    - 文档表示模型\n",
    "        * Plain BOW：直接用词袋向量表示每一篇文档，向量中每个维度的值为该词的 TF \\* IDF 值\n",
    "        * LSA：潜在语义分析\n",
    "        * LDA：Latent Dirichlet Allocation，隐含狄利克雷分布\n",
    "        * arithmatic mean representation：均值表示法，即将该文档中每个词的词嵌入向量相加后求均值，用均值向量来表示文档\n",
    "        * word-clustering (pure count)：基于词嵌入向量的聚类表示（基于计数），又称「概念袋」（Bag-of-Concepts）法（基于计数）\n",
    "        * word-clustering (TF\\*IDF)：基于词嵌入向量的聚类表示（基于TF\\*IDF），又称「概念袋」（Bag-of-Concepts）法（基于 TF\\*IDF）\n",
    "        * Doc2Vec：文档嵌入向量表示\n",
    "    - 分类器训练法\n",
    "        * SVM：Support Vector Machine，支持向量机\n",
    "        * NB(Gaussian NB)：NB(Naive Bayes) 朴素贝叶斯；Gaussian NB 高斯朴素贝叶斯（认为特征项服从于高斯分布，即正态分布）\n",
    "        * RF：RandomForest，随机森林\n",
    "        * DNN：Deep Neural Network，深度神经网络（普通的多层感知机构成的多层神经网络）\n",
    "        * CNN：Convolution Neural Network，卷积神经网络\n",
    "+ 训练工具\n",
    "    - 词汇模型\n",
    "        * BOW+TF-IDF：使用 scikit-learn 建模\n",
    "        * Word2Vec：使用 gensim 与 TensorFlow 建模\n",
    "    - 文档表示模型\n",
    "        * sklearn\n",
    "        * 手动编写代码\n",
    "    - 分类器训练法\n",
    "        * 传统算法：SVM, LSA, LDA 使用 scikit-learn 训练\n",
    "        * 神经网络算法：DNN, CNN：使用 TensorFlow 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 实验流程规划\n",
    "\n",
    "1. 模块导入\n",
    "2. 数据预处理（通用预处理）\n",
    "  + 对文本进行清洗，包括但不限于去除特殊符号、进行大小写转换等工作，最终使文本中只包含：由小写字母 a-z 组成的单词、单一空格\n",
    "  + 不在 a-z 之间的字符将一律被转换为空格\n",
    "3. 文本表示建模\n",
    "  + 不基于任何词汇表示，直接使用 Doc2Vec 建立文档嵌入向量\n",
    "  + 基于 BOW 词汇表示，使用 TF-IDF 建立 3 种文档表示模型：\n",
    "      1. 读入原始语料并保存\n",
    "      2. 使用 scikit-learn，在原始语料的基础上，进行建立词袋（BOW）、计算 TF-IDF\n",
    "      3. 文档表示建模\n",
    "          - 【法 1】通过使用 BOW+TF-IDF 向量表示文档中的每个词，从而表示每篇文档（包括所有语料：训练集和测试集）\n",
    "          - 【法 2】通过在由 BOW+TF-IDF 向量组成的矩阵上进行 LSA，从而表示每篇文档（包括所有语料：训练集和测试集）\n",
    "          - 【法 2】通过在由 BOW+TF-IDF 向量组成的矩阵上进行 LDA，从而表示每篇文档（包括所有语料：训练集和测试集）\n",
    "  + 基于 Word2Vec 词汇表示，使用 3 种方法建立文档表示模型：\n",
    "      1. 分别使用 gensim 和 TensorFlow 中的每一种，分别在 text8 的基础上、在待学习样本（corpus）的基础上，建立词嵌入（word embedding）模型：Word2Vec\n",
    "          + 即：训练出 gensim+text8, gensim+待学习样本, TensorFlow+text8, TensorFlow+待学习样本 共计 4 种表示模型\n",
    "          + 使用 Skip-Gram 方法进行建模\n",
    "      2. 文档表示建模\n",
    "          + 【法 1】通过使用 Word2Vec 向量表示文档中的每个词，求这些词向量的和，对于求和向量进行求算术平均，使用算术平均向量表示每一篇文档\n",
    "              - 对于不在词汇表中的词，以某常量代替——具体而言，可指定为加入零向量，或在求和向量乘上某个常量系数\n",
    "          + 【法 2】通过对学习到的 Word2Vec 向量进行聚类，得到若干「概念袋」（Bag-of-Concepts）（类比「词袋」，Bag-of-Concepts），用然后对「概念袋」的每一个维度进行计数（遍历文档中的每个词，聚类预测其所在的「概念维度」），从而表示每一篇文档\n",
    "              - 对于不在词汇表中的词，可以指向同一维度 `UNK` 进行计数，最后的 「概念袋」中可考虑使用或不使用该维度来表示文档\n",
    "          + 【法 3】同上述学习「概念袋」（Bag-of-Concepts）的过程，区别在于：表示出基于计数的「概念袋」后，先进行 TF\\*IDF 计算，然后用 TF\\*IDF 值来表示每一篇文档\n",
    "      3. 在使用神经网络算法进行训练前，对每篇文档对应的标签独热（one-hot）向量化\n",
    "4. 分类器训练\n",
    "  + 传统算法：SVM, LSA, LDA 使用 scikit-learn 训练\n",
    "  + 神经网络算法：DNN, CNN：使用 TensorFlow 训练\n",
    "5. 分类器评估\n",
    "  + 对于传统算法：\n",
    "    - 使用 sckit-learn 提供的 GridSearchCV 与 LearningCurve 方法寻找最优参数组合\n",
    "    - 使用 scikit-learn 提供的 accuracy_score（查准率 P） 与 f1_score（F1 分数，同时考察了查准率 P 与查全率 R） 评估训练结果\n",
    "  + 对于神经网络算法：\n",
    "    - 暂定手工选择一组参数进行训练；待考察是否可使用 GridSearchCV 与 LearningCurve 进行参数组合寻找最优参数组合\n",
    "    - 暂定使用手工编写的方法计算查准率 P、查全率 R、F1 分数；待考察是否可对数据格式进行一定程度上的转换或存储，以使用上述提及的 scikit-learn 提供的评估工具"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 实验记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy(%)': {}, 'model.source': {}, 'model.word': {}, 'tool.word': {}, 'model.document': {}, 'tool.document': {}, 'classifier': {}, 'time.raw.model': {}, 'time.raw.train': {}, 'time.raw.evaluate': {}, 'time.raw.all': {}, 'time.format.model': {}, 'time.format.train': {}, 'time.format.evaluate': {}, 'time.format.all': {}}\n",
      "['accuracy(%)', 'model.source', 'model.word', 'tool.word', 'model.document', 'tool.document', 'classifier', 'time.raw.model', 'time.raw.train', 'time.raw.evaluate', 'time.raw.all', 'time.format.model', 'time.format.train', 'time.format.evaluate', 'time.format.all']\n",
      "\n",
      "Data structure for recording experiment data created.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run Experiment-exploration-init.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 BOW+TF-IDF 表示法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 普通 VSM 表示模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>参数列表</center>\n",
    "\n",
    "参数 |  取值\n",
    "--------|-----------\n",
    "max_df | 0.9\n",
    "min_df | 0.01\n",
    "max_features | 784\n",
    "analyzer | 'word'\n",
    "stop_words | stopwordlist（来自文件）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### SVM classifier(BOW+TFIDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### GaussianNB classifier(BOW+TFIDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### RF classifier(BOW+TFIDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Output stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 基于 BOW+TFIDF 的 LSA 表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>参数列表</center>\n",
    "\n",
    "参数 |  取值\n",
    "--------|-----------\n",
    "k(n_components) | 200\n",
    "n_iter | 10\n",
    "random_state | 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SVM classifier(BOW+TFIDF+LSA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### GaussianNB classifier(BOW+TFIDF+LSA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### RF classifier(BOW+TFIDF+LSA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 基于 BOW+TFIDF 的 LDA 表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>参数列表</center>\n",
    "\n",
    "参数 |  取值\n",
    "--------|-----------\n",
    "n_topic | 50\n",
    "max_iter | 10\n",
    "random_state | 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 注意：实验表明，主题数的选择会影响训练效果。目前测试过 5, 35, 50, 75, 100, 200，似乎以 50 效果最好。因此最后保留 50 的训练结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SVM classifier(BOW+TFIDF+LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### GaussianNB classifier(BOW+TFIDF+LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### RF classifier(BOW+TFIDF+LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Word2Vec 表示法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 gensim 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.1.1 基于 text8 建模"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SVM classifier(gensim + text8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### DNN classifier(gensim + text8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### CNN classifier(gensim + text8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.1.2 只用待学习语料建模"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SVM classifier(gensim + corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### DNN classifier(gensim + corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### CNN classifier(gensim + corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 TensorFlow 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.1.1 基于 text8 建模"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SVM classifier(TensorFlow + text8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### DNN classifier(TensorFlow + text8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### CNN classifier(TensorFlow + text8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.1.2 只用待学习语料建模"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SVM classifier(TensorFlow + corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### DNN classifier(TensorFlow + corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### CNN classifier(TensorFlow + corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Doc2Vec 表示法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SVM classifier(gensim + text8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### DNN classifier(gensim + text8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### CNN classifier(gensim + text8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 数据总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 在本次小试中，仅以查准率（Precision，也译作「精度」）作为训练效果度量。实际完成 20 分类的任务时，应使用 $F_{1}$ 进行性能度量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 以传统算法中的 SVM 为分类器为例，比较 3 类表示模型对结果的影响（词袋表示、词嵌入表示、文档嵌入表示）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次小试训练了在不同文本表示模型上的 5 种分类器，包括 3 种传统分类器（支持向量机 SVM，高斯朴素贝叶斯分类器 GaussianNB，随机森林分类器 RandomForest）与 2 种神经网络分类器（深度神经网络 DNN，卷积神经网络 CNN）。各种分类器在不同文本表示模型上的训练结果如下列各表格所示，小结如下：\n",
    "\n",
    "#### 5.1.1 对于同种分类器，不同表示模型会对训练结果造成影响\n",
    "\n",
    "+ 从**训练效果**上看：\n",
    "    - 查看标准差（`std`）：\n",
    "        * CNN 受文本表示模型的影响最小，GaussianNB 受文本表示模型的影响最大。\n",
    "            - 该结论的成立依赖于忽略下述事实：神经网络分类器仅在 2 种文本表示模型（两种词嵌入模型，即：基于 text8 训练的词向量均值表示；基于待学习语料训练的词向量均值表示）下进行训练，而传统分类器在 5 种文本表示模型（BOW+TFIDF 的直接表示，BOW+TFIDF+LSA，BOW+TFIDF+LDA，以及上述两种词嵌入模型）\n",
    "        * 若考虑上述事实（传统算法在更多的文本表示模型上进行训练，因而变化的可能性更大），则\n",
    "            - 传统分类器中：SVM 受文本表示模型的影响最小，GaussianNB 受文本表示模型的影响最大\n",
    "            - 神经网络分类器种：CNN 比 DNN 受文本表示模型的影响更小\n",
    "            \n",
    "。。。待续"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 对同一种分类器，使用 Word2Vec 作为词嵌入模型表示文本，比较不同训练工具对结果的影响（gensim、TensorFlow）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3  对同一种分类器，使用 Word2Vec 作为词嵌入模型表示文本，比较用于建立词嵌入模型的不同训练语料对结果的影响（corpus、text8）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 综合来看，「表示模型（传统模型/词嵌入模型、训练工具、训练语料） + 分类器」组合的效果评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> + 挑选 2 类表示模型，每类表示模型中挑选出 2 种分类器，共计 4 种「表示模型 + 分类器」的组合，将用于最终的 20 分类任务\n",
    "> + 若选择了 Word2Vec，从 gensim 与 TensorFlow 中挑选出一种来建立词嵌入向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 展望"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 可以（对每种表示模型训练器）实现实现一种类似 [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) 的模块，从而用于从「表示器 + 分类器」的组合种进行自动评分从而进行参数筛选\n",
    "2. 或许可以尝试使用 RNN 来完成分类\n",
    "3. 。。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
